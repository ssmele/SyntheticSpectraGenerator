{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthetic_torch_helpers import SynH5Dataset, ConvModSyn, H5Dataset\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Loss, Metric, Accuracy\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in Eboss Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eboss = H5Dataset(\"../astrogravlensing/Data/eboss_flux_full+.hdf5\", keys=['res_flux_values', 'flux_labels'], load_to_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eboss.res_flux_values = eboss.res_flux_values[:, np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281, 1, 4639)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eboss.res_flux_values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Centering the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eboss.res_flux_values -= np.mean(eboss.res_flux_values, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_mss = MinMaxScaler()\n",
    "eboss.res_flux_values = flux_mss.fit_transform(eboss.res_flux_values[:, 0, :]).reshape(-1, 1, 4639)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(eboss, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvModSyn(\n",
       "  (conv_layers): Sequential(\n",
       "    (conv_0): Sequential(\n",
       "      (0): Conv1d(1, 64, kernel_size=(10,), stride=(1,))\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv_1): Sequential(\n",
       "      (0): Conv1d(64, 32, kernel_size=(10,), stride=(1,))\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv_2): Sequential(\n",
       "      (0): Conv1d(32, 12, kernel_size=(2,), stride=(1,))\n",
       "      (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv_3): Sequential(\n",
       "      (0): Conv1d(12, 6, kernel_size=(5,), stride=(1,))\n",
       "      (1): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (pool_3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (fc_0): Sequential(\n",
       "      (0): Linear(in_features=6912, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (dropout_0): Dropout(p=0.5)\n",
       "    (fc_1): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (dropout_1): Dropout(p=0.5)\n",
       "    (fc_4): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (final_act): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_config = [\n",
    "    (1, 64, 10),\n",
    "    (64, 32, 10),\n",
    "# Max Pooling\n",
    "    (32, 12, 2),\n",
    "    (12, 6, 5),\n",
    "]\n",
    "pooling_ixs = {1 : 2, 3: 2}\n",
    "\n",
    "\n",
    "full_config = [\n",
    "    (6912, 1024),\n",
    "    # Dropout\n",
    "    (1024, 512),\n",
    "    (512, 1)\n",
    "]\n",
    "dropout_ixs = {0: .5, 1 : .5}\n",
    "\n",
    "mod = ConvModSyn(conv_config, full_config, pooling_ixs, dropout_ixs, torch.nn.Sigmoid())\n",
    "mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(mod.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up gpu device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up trainer and evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholded_output_transform(output):\n",
    "    y_pred, y = output[0], output[1]\n",
    "    y_pred = torch.round(y_pred)\n",
    "    return y_pred, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = create_supervised_trainer(mod, opt, loss, device=device)\n",
    "evaluator = create_supervised_evaluator(mod, metrics={'bce': Loss(loss), 'acc': Accuracy(output_transform=thresholded_output_transform)}, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saver = ModelCheckpoint(\"./models_lensing/sess_{}/\".format(datetime.datetime.now()), \"reg\", create_dir=True, \n",
    "                              score_function=lambda eng: eng.state.train_loss, score_name='t_loss', n_saved=5)\n",
    "early_stopper = EarlyStopping(20, score_function=lambda eng: eng.state.train_loss, trainer=trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Events (Experimenting with ignite for pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_level = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(trainer):\n",
    "    if (trainer.state.iteration-1) % iter_level == 0:\n",
    "        print(\"Epoch[{}], Iter: {}, Loss: {:.5f}\".format(trainer.state.epoch, trainer.state.iteration, trainer.state.output))\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    evaluator.run(train_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    trainer.state.train_loss = metrics['bce']\n",
    "    trainer.state.train_acc = metrics['acc']\n",
    "    print(\"Training Results - Epoch: {}, Accuracy: {:.5f}, Avg loss: {:.5f}\".format(trainer.state.epoch, metrics['acc'], metrics['bce']))\n",
    "\n",
    "# @trainer.on(Events.EPOCH_COMPLETED)\n",
    "# def log_validation_results(trainer):\n",
    "#     evaluator.run(val_loader)\n",
    "#     metrics = evaluator.state.metrics\n",
    "#     trainer.state.val_loss = metrics['bce']\n",
    "#     print(\"Validation Results - Epoch: {}, SciStandard: {:.5f}, Avg loss: {:.5f}\".format(trainer.state.epoch, metrics['sci'], metrics['mse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, model_saver, {'mod': mod})\n",
    "# trainer.add_event_handler(Events.EPOCH_COMPLETED, early_stopper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1], Iter: 1, Loss: 0.19009\n",
      "Epoch[1], Iter: 4, Loss: 0.65826\n",
      "Epoch[1], Iter: 7, Loss: 0.08786\n",
      "Epoch[1], Iter: 10, Loss: 0.04918\n",
      "Epoch[1], Iter: 13, Loss: 0.11345\n",
      "Epoch[1], Iter: 16, Loss: 0.24549\n",
      "Epoch[1], Iter: 19, Loss: 0.43425\n",
      "Epoch[1], Iter: 22, Loss: 0.15402\n",
      "Epoch[1], Iter: 25, Loss: 0.29196\n",
      "Epoch[1], Iter: 28, Loss: 0.10831\n",
      "Epoch[1], Iter: 31, Loss: 0.18792\n",
      "Epoch[1], Iter: 34, Loss: 0.13253\n",
      "Training Results - Epoch: 1, Accuracy: 0.89680, Avg loss: 0.16054\n",
      "Epoch[2], Iter: 37, Loss: 0.24589\n",
      "Epoch[2], Iter: 40, Loss: 0.24803\n",
      "Epoch[2], Iter: 43, Loss: 0.12650\n",
      "Epoch[2], Iter: 46, Loss: 0.38497\n",
      "Epoch[2], Iter: 49, Loss: 0.04383\n",
      "Epoch[2], Iter: 52, Loss: 0.00165\n",
      "Epoch[2], Iter: 55, Loss: 0.36510\n",
      "Epoch[2], Iter: 58, Loss: 0.07182\n",
      "Epoch[2], Iter: 61, Loss: 0.20960\n",
      "Epoch[2], Iter: 64, Loss: 0.24445\n",
      "Epoch[2], Iter: 67, Loss: 0.00604\n",
      "Epoch[2], Iter: 70, Loss: 0.70659\n",
      "Training Results - Epoch: 2, Accuracy: 0.97509, Avg loss: 0.09561\n",
      "Epoch[3], Iter: 73, Loss: 0.28930\n",
      "Epoch[3], Iter: 76, Loss: 0.16155\n",
      "Epoch[3], Iter: 79, Loss: 0.04265\n",
      "Epoch[3], Iter: 82, Loss: 0.07640\n",
      "Epoch[3], Iter: 85, Loss: 0.06936\n",
      "Epoch[3], Iter: 88, Loss: 0.02942\n",
      "Epoch[3], Iter: 91, Loss: 0.00260\n",
      "Epoch[3], Iter: 94, Loss: 0.22943\n",
      "Epoch[3], Iter: 97, Loss: 0.17161\n",
      "Epoch[3], Iter: 100, Loss: 0.07018\n",
      "Epoch[3], Iter: 103, Loss: 0.01698\n",
      "Epoch[3], Iter: 106, Loss: 0.05649\n",
      "Training Results - Epoch: 3, Accuracy: 0.97509, Avg loss: 0.07881\n",
      "Epoch[4], Iter: 109, Loss: 0.04662\n",
      "Epoch[4], Iter: 112, Loss: 0.01991\n",
      "Epoch[4], Iter: 115, Loss: 0.00891\n",
      "Epoch[4], Iter: 118, Loss: 0.07861\n",
      "Epoch[4], Iter: 121, Loss: 0.04150\n",
      "Epoch[4], Iter: 124, Loss: 0.39961\n",
      "Epoch[4], Iter: 127, Loss: 0.31502\n",
      "Epoch[4], Iter: 130, Loss: 0.06374\n",
      "Epoch[4], Iter: 133, Loss: 0.09114\n",
      "Epoch[4], Iter: 136, Loss: 0.08147\n",
      "Epoch[4], Iter: 139, Loss: 0.03773\n",
      "Epoch[4], Iter: 142, Loss: 0.11278\n",
      "Training Results - Epoch: 4, Accuracy: 0.98221, Avg loss: 0.04421\n",
      "Epoch[5], Iter: 145, Loss: 0.06980\n",
      "Epoch[5], Iter: 148, Loss: 0.11534\n",
      "Epoch[5], Iter: 151, Loss: 0.00259\n",
      "Epoch[5], Iter: 154, Loss: 0.04033\n",
      "Epoch[5], Iter: 157, Loss: 0.01321\n",
      "Epoch[5], Iter: 160, Loss: 0.10517\n",
      "Epoch[5], Iter: 163, Loss: 0.07512\n",
      "Epoch[5], Iter: 166, Loss: 0.00689\n",
      "Epoch[5], Iter: 169, Loss: 0.00596\n",
      "Epoch[5], Iter: 172, Loss: 0.00703\n",
      "Epoch[5], Iter: 175, Loss: 0.00034\n",
      "Epoch[5], Iter: 178, Loss: 0.00713\n",
      "Training Results - Epoch: 5, Accuracy: 0.99288, Avg loss: 0.03656\n",
      "Epoch[6], Iter: 181, Loss: 0.00814\n",
      "Epoch[6], Iter: 184, Loss: 0.00742\n",
      "Epoch[6], Iter: 187, Loss: 0.00406\n",
      "Epoch[6], Iter: 190, Loss: 0.02078\n",
      "Epoch[6], Iter: 193, Loss: 0.00813\n",
      "Epoch[6], Iter: 196, Loss: 0.02611\n",
      "Epoch[6], Iter: 199, Loss: 0.02864\n",
      "Epoch[6], Iter: 202, Loss: 0.00487\n",
      "Epoch[6], Iter: 205, Loss: 0.03106\n",
      "Epoch[6], Iter: 208, Loss: 0.12844\n",
      "Epoch[6], Iter: 211, Loss: 0.03006\n",
      "Epoch[6], Iter: 214, Loss: 0.20141\n",
      "Training Results - Epoch: 6, Accuracy: 0.98932, Avg loss: 0.01968\n",
      "Epoch[7], Iter: 217, Loss: 0.02174\n",
      "Epoch[7], Iter: 220, Loss: 0.11025\n",
      "Epoch[7], Iter: 223, Loss: 0.00056\n",
      "Epoch[7], Iter: 226, Loss: 0.00062\n",
      "Epoch[7], Iter: 229, Loss: 0.00244\n",
      "Epoch[7], Iter: 232, Loss: 0.00631\n",
      "Epoch[7], Iter: 235, Loss: 0.00356\n",
      "Epoch[7], Iter: 238, Loss: 0.07110\n",
      "Epoch[7], Iter: 241, Loss: 0.00167\n",
      "Epoch[7], Iter: 244, Loss: 0.01159\n",
      "Epoch[7], Iter: 247, Loss: 0.02662\n",
      "Epoch[7], Iter: 250, Loss: 0.22156\n",
      "Training Results - Epoch: 7, Accuracy: 0.99644, Avg loss: 0.01754\n",
      "Epoch[8], Iter: 253, Loss: 0.00378\n",
      "Epoch[8], Iter: 256, Loss: 0.00789\n",
      "Epoch[8], Iter: 259, Loss: 0.04982\n",
      "Epoch[8], Iter: 262, Loss: 0.02729\n",
      "Epoch[8], Iter: 265, Loss: 0.00511\n",
      "Epoch[8], Iter: 268, Loss: 0.01320\n",
      "Epoch[8], Iter: 271, Loss: 0.00399\n",
      "Epoch[8], Iter: 274, Loss: 0.00158\n",
      "Epoch[8], Iter: 277, Loss: 0.00423\n",
      "Epoch[8], Iter: 280, Loss: 0.01034\n",
      "Epoch[8], Iter: 283, Loss: 0.01199\n",
      "Epoch[8], Iter: 286, Loss: 0.00296\n",
      "Training Results - Epoch: 8, Accuracy: 0.99288, Avg loss: 0.01327\n",
      "Epoch[9], Iter: 289, Loss: 0.00627\n",
      "Epoch[9], Iter: 292, Loss: 0.00547\n",
      "Epoch[9], Iter: 295, Loss: 0.00642\n",
      "Epoch[9], Iter: 298, Loss: 0.00634\n",
      "Epoch[9], Iter: 301, Loss: 0.02978\n",
      "Epoch[9], Iter: 304, Loss: 0.00476\n",
      "Epoch[9], Iter: 307, Loss: 0.00969\n",
      "Epoch[9], Iter: 310, Loss: 0.00782\n",
      "Epoch[9], Iter: 313, Loss: 0.00092\n",
      "Epoch[9], Iter: 316, Loss: 0.00290\n",
      "Epoch[9], Iter: 319, Loss: 0.00237\n",
      "Epoch[9], Iter: 322, Loss: 0.00114\n",
      "Training Results - Epoch: 9, Accuracy: 1.00000, Avg loss: 0.00678\n",
      "Epoch[10], Iter: 325, Loss: 0.03677\n",
      "Epoch[10], Iter: 328, Loss: 0.06780\n",
      "Epoch[10], Iter: 331, Loss: 0.02828\n",
      "Epoch[10], Iter: 334, Loss: 0.13261\n",
      "Epoch[10], Iter: 337, Loss: 0.02619\n",
      "Epoch[10], Iter: 340, Loss: 0.03104\n",
      "Epoch[10], Iter: 343, Loss: 0.00144\n",
      "Epoch[10], Iter: 346, Loss: 0.01900\n",
      "Epoch[10], Iter: 349, Loss: 0.00116\n",
      "Epoch[10], Iter: 352, Loss: 0.00907\n",
      "Epoch[10], Iter: 355, Loss: 0.00485\n",
      "Epoch[10], Iter: 358, Loss: 0.00305\n",
      "Training Results - Epoch: 10, Accuracy: 0.99644, Avg loss: 0.01050\n",
      "Epoch[11], Iter: 361, Loss: 0.01271\n",
      "Epoch[11], Iter: 364, Loss: 0.11910\n",
      "Epoch[11], Iter: 367, Loss: 0.01315\n",
      "Epoch[11], Iter: 370, Loss: 0.00094\n",
      "Epoch[11], Iter: 373, Loss: 0.00742\n",
      "Epoch[11], Iter: 376, Loss: 0.00093\n",
      "Epoch[11], Iter: 379, Loss: 0.00032\n",
      "Epoch[11], Iter: 382, Loss: 0.00834\n",
      "Epoch[11], Iter: 385, Loss: 0.02140\n",
      "Epoch[11], Iter: 388, Loss: 0.00222\n",
      "Epoch[11], Iter: 391, Loss: 0.00066\n",
      "Epoch[11], Iter: 394, Loss: 0.00105\n",
      "Training Results - Epoch: 11, Accuracy: 1.00000, Avg loss: 0.00627\n",
      "Epoch[12], Iter: 397, Loss: 0.00162\n",
      "Epoch[12], Iter: 400, Loss: 0.00742\n",
      "Epoch[12], Iter: 403, Loss: 0.10543\n",
      "Epoch[12], Iter: 406, Loss: 0.00004\n",
      "Epoch[12], Iter: 409, Loss: 0.00603\n",
      "Epoch[12], Iter: 412, Loss: 0.00355\n",
      "Epoch[12], Iter: 415, Loss: 0.00131\n",
      "Epoch[12], Iter: 418, Loss: 0.02219\n",
      "Epoch[12], Iter: 421, Loss: 0.00431\n",
      "Epoch[12], Iter: 424, Loss: 0.00012\n",
      "Epoch[12], Iter: 427, Loss: 0.01074\n",
      "Epoch[12], Iter: 430, Loss: 0.00202\n",
      "Training Results - Epoch: 12, Accuracy: 1.00000, Avg loss: 0.00188\n",
      "Epoch[13], Iter: 433, Loss: 0.00088\n",
      "Epoch[13], Iter: 436, Loss: 0.01770\n",
      "Epoch[13], Iter: 439, Loss: 0.00393\n",
      "Epoch[13], Iter: 442, Loss: 0.00016\n",
      "Epoch[13], Iter: 445, Loss: 0.00058\n",
      "Epoch[13], Iter: 448, Loss: 0.00492\n",
      "Epoch[13], Iter: 451, Loss: 0.00004\n",
      "Epoch[13], Iter: 454, Loss: 0.00179\n",
      "Epoch[13], Iter: 457, Loss: 0.00053\n",
      "Epoch[13], Iter: 460, Loss: 0.00015\n",
      "Epoch[13], Iter: 463, Loss: 0.00277\n",
      "Epoch[13], Iter: 466, Loss: 0.00580\n",
      "Training Results - Epoch: 13, Accuracy: 1.00000, Avg loss: 0.00126\n",
      "Epoch[14], Iter: 469, Loss: 0.00017\n",
      "Epoch[14], Iter: 472, Loss: 0.00060\n",
      "Epoch[14], Iter: 475, Loss: 0.00112\n",
      "Epoch[14], Iter: 478, Loss: 0.00046\n",
      "Epoch[14], Iter: 481, Loss: 0.00014\n",
      "Epoch[14], Iter: 484, Loss: 0.00974\n",
      "Epoch[14], Iter: 487, Loss: 0.01378\n",
      "Epoch[14], Iter: 490, Loss: 0.01127\n",
      "Epoch[14], Iter: 493, Loss: 0.00013\n",
      "Epoch[14], Iter: 496, Loss: 0.05585\n",
      "Epoch[14], Iter: 499, Loss: 0.00002\n",
      "Epoch[14], Iter: 502, Loss: 0.00319\n",
      "Training Results - Epoch: 14, Accuracy: 1.00000, Avg loss: 0.00168\n",
      "Epoch[15], Iter: 505, Loss: 0.00132\n",
      "Epoch[15], Iter: 508, Loss: 0.00631\n",
      "Epoch[15], Iter: 511, Loss: 0.06758\n",
      "Epoch[15], Iter: 514, Loss: 0.00023\n",
      "Epoch[15], Iter: 517, Loss: 0.00120\n",
      "Epoch[15], Iter: 520, Loss: 0.00006\n",
      "Epoch[15], Iter: 523, Loss: 0.00121\n",
      "Epoch[15], Iter: 526, Loss: 0.01576\n",
      "Epoch[15], Iter: 529, Loss: 0.00683\n",
      "Epoch[15], Iter: 532, Loss: 0.00222\n",
      "Epoch[15], Iter: 535, Loss: 0.00013\n",
      "Epoch[15], Iter: 538, Loss: 0.00265\n",
      "Training Results - Epoch: 15, Accuracy: 1.00000, Avg loss: 0.00060\n",
      "Epoch[16], Iter: 541, Loss: 0.00181\n",
      "Epoch[16], Iter: 544, Loss: 0.00008\n",
      "Epoch[16], Iter: 547, Loss: 0.00345\n",
      "Epoch[16], Iter: 550, Loss: 0.00012\n",
      "Epoch[16], Iter: 553, Loss: 0.00000\n",
      "Epoch[16], Iter: 556, Loss: 0.00145\n",
      "Epoch[16], Iter: 559, Loss: 0.00119\n",
      "Epoch[16], Iter: 562, Loss: 0.00007\n",
      "Epoch[16], Iter: 565, Loss: 0.00129\n",
      "Epoch[16], Iter: 568, Loss: 0.00140\n",
      "Epoch[16], Iter: 571, Loss: 0.00086\n",
      "Epoch[16], Iter: 574, Loss: 0.00001\n",
      "Training Results - Epoch: 16, Accuracy: 1.00000, Avg loss: 0.00043\n",
      "Epoch[17], Iter: 577, Loss: 0.00045\n",
      "Epoch[17], Iter: 580, Loss: 0.00002\n",
      "Epoch[17], Iter: 583, Loss: 0.00261\n",
      "Epoch[17], Iter: 586, Loss: 0.00073\n",
      "Epoch[17], Iter: 589, Loss: 0.00112\n",
      "Epoch[17], Iter: 592, Loss: 0.00036\n",
      "Epoch[17], Iter: 595, Loss: 0.00188\n",
      "Epoch[17], Iter: 598, Loss: 0.00259\n",
      "Epoch[17], Iter: 601, Loss: 0.00001\n",
      "Epoch[17], Iter: 604, Loss: 0.00378\n",
      "Epoch[17], Iter: 607, Loss: 0.00057\n",
      "Epoch[17], Iter: 610, Loss: 0.00261\n",
      "Training Results - Epoch: 17, Accuracy: 1.00000, Avg loss: 0.00033\n",
      "Epoch[18], Iter: 613, Loss: 0.00013\n",
      "Epoch[18], Iter: 616, Loss: 0.00001\n",
      "Epoch[18], Iter: 619, Loss: 0.00075\n",
      "Epoch[18], Iter: 622, Loss: 0.00599\n",
      "Epoch[18], Iter: 625, Loss: 0.00044\n",
      "Epoch[18], Iter: 628, Loss: 0.01189\n",
      "Epoch[18], Iter: 631, Loss: 0.00017\n",
      "Epoch[18], Iter: 634, Loss: 0.00062\n",
      "Epoch[18], Iter: 637, Loss: 0.00047\n",
      "Epoch[18], Iter: 640, Loss: 0.00404\n",
      "Epoch[18], Iter: 643, Loss: 0.00134\n",
      "Epoch[18], Iter: 646, Loss: 0.00006\n",
      "Training Results - Epoch: 18, Accuracy: 1.00000, Avg loss: 0.00055\n",
      "Epoch[19], Iter: 649, Loss: 0.00396\n",
      "Epoch[19], Iter: 652, Loss: 0.00077\n",
      "Epoch[19], Iter: 655, Loss: 0.00039\n",
      "Epoch[19], Iter: 658, Loss: 0.00500\n",
      "Epoch[19], Iter: 661, Loss: 0.00004\n",
      "Epoch[19], Iter: 664, Loss: 0.00000\n",
      "Epoch[19], Iter: 667, Loss: 0.00006\n",
      "Epoch[19], Iter: 670, Loss: 0.00020\n",
      "Epoch[19], Iter: 673, Loss: 0.00205\n",
      "Epoch[19], Iter: 676, Loss: 0.00131\n",
      "Epoch[19], Iter: 679, Loss: 0.00040\n",
      "Epoch[19], Iter: 682, Loss: 0.00020\n",
      "Training Results - Epoch: 19, Accuracy: 1.00000, Avg loss: 0.00023\n",
      "Epoch[20], Iter: 685, Loss: 0.00142\n",
      "Epoch[20], Iter: 688, Loss: 0.00180\n",
      "Epoch[20], Iter: 691, Loss: 0.00002\n",
      "Epoch[20], Iter: 694, Loss: 0.00007\n",
      "Epoch[20], Iter: 697, Loss: 0.00005\n",
      "Epoch[20], Iter: 700, Loss: 0.00006\n",
      "Epoch[20], Iter: 703, Loss: 0.00151\n",
      "Epoch[20], Iter: 706, Loss: 0.00121\n",
      "Epoch[20], Iter: 709, Loss: 0.00096\n",
      "Epoch[20], Iter: 712, Loss: 0.00291\n",
      "Epoch[20], Iter: 715, Loss: 0.00002\n",
      "Epoch[20], Iter: 718, Loss: 0.00020\n",
      "Training Results - Epoch: 20, Accuracy: 1.00000, Avg loss: 0.00021\n",
      "Epoch[21], Iter: 721, Loss: 0.00037\n",
      "Epoch[21], Iter: 724, Loss: 0.00000\n",
      "Epoch[21], Iter: 727, Loss: 0.00029\n",
      "Epoch[21], Iter: 730, Loss: 0.00017\n",
      "Epoch[21], Iter: 733, Loss: 0.00006\n",
      "Epoch[21], Iter: 736, Loss: 0.00056\n",
      "Epoch[21], Iter: 739, Loss: 0.00003\n",
      "Epoch[21], Iter: 742, Loss: 0.00055\n",
      "Epoch[21], Iter: 745, Loss: 0.00009\n",
      "Epoch[21], Iter: 748, Loss: 0.00014\n",
      "Epoch[21], Iter: 751, Loss: 0.00012\n",
      "Epoch[21], Iter: 754, Loss: 0.00010\n",
      "Training Results - Epoch: 21, Accuracy: 1.00000, Avg loss: 0.00014\n",
      "Epoch[22], Iter: 757, Loss: 0.00007\n",
      "Epoch[22], Iter: 760, Loss: 0.00007\n",
      "Epoch[22], Iter: 763, Loss: 0.00064\n",
      "Epoch[22], Iter: 766, Loss: 0.00023\n",
      "Epoch[22], Iter: 769, Loss: 0.00035\n",
      "Epoch[22], Iter: 772, Loss: 0.00020\n",
      "Epoch[22], Iter: 775, Loss: 0.00011\n",
      "Epoch[22], Iter: 778, Loss: 0.00112\n",
      "Epoch[22], Iter: 781, Loss: 0.00101\n",
      "Epoch[22], Iter: 784, Loss: 0.00000\n",
      "Epoch[22], Iter: 787, Loss: 0.00039\n",
      "Epoch[22], Iter: 790, Loss: 0.00012\n",
      "Training Results - Epoch: 22, Accuracy: 1.00000, Avg loss: 0.00014\n",
      "Epoch[23], Iter: 793, Loss: 0.00138\n",
      "Epoch[23], Iter: 796, Loss: 0.00021\n",
      "Epoch[23], Iter: 799, Loss: 0.00015\n",
      "Epoch[23], Iter: 802, Loss: 0.00058\n",
      "Epoch[23], Iter: 805, Loss: 0.00012\n",
      "Epoch[23], Iter: 808, Loss: 0.00027\n",
      "Epoch[23], Iter: 811, Loss: 0.00027\n",
      "Epoch[23], Iter: 814, Loss: 0.00021\n",
      "Epoch[23], Iter: 817, Loss: 0.00008\n",
      "Epoch[23], Iter: 820, Loss: 0.00007\n",
      "Epoch[23], Iter: 823, Loss: 0.00088\n",
      "Epoch[23], Iter: 826, Loss: 0.00183\n",
      "Training Results - Epoch: 23, Accuracy: 1.00000, Avg loss: 0.00012\n",
      "Epoch[24], Iter: 829, Loss: 0.00015\n",
      "Epoch[24], Iter: 832, Loss: 0.00071\n",
      "Epoch[24], Iter: 835, Loss: 0.00041\n",
      "Epoch[24], Iter: 838, Loss: 0.00275\n",
      "Epoch[24], Iter: 841, Loss: 0.00005\n",
      "Epoch[24], Iter: 844, Loss: 0.00863\n",
      "Epoch[24], Iter: 847, Loss: 0.00106\n",
      "Epoch[24], Iter: 850, Loss: 0.00167\n",
      "Epoch[24], Iter: 853, Loss: 0.00022\n",
      "Epoch[24], Iter: 856, Loss: 0.00025\n",
      "Epoch[24], Iter: 859, Loss: 0.00002\n",
      "Epoch[24], Iter: 862, Loss: 0.00040\n",
      "Training Results - Epoch: 24, Accuracy: 1.00000, Avg loss: 0.00018\n",
      "Epoch[25], Iter: 865, Loss: 0.00000\n",
      "Epoch[25], Iter: 868, Loss: 0.00004\n",
      "Epoch[25], Iter: 871, Loss: 0.00055\n",
      "Epoch[25], Iter: 874, Loss: 0.00019\n",
      "Epoch[25], Iter: 877, Loss: 0.00020\n",
      "Epoch[25], Iter: 880, Loss: 0.00039\n",
      "Epoch[25], Iter: 883, Loss: 0.00048\n",
      "Epoch[25], Iter: 886, Loss: 0.00018\n",
      "Epoch[25], Iter: 889, Loss: 0.00024\n",
      "Epoch[25], Iter: 892, Loss: 0.00003\n",
      "Epoch[25], Iter: 895, Loss: 0.00026\n",
      "Epoch[25], Iter: 898, Loss: 0.00002\n",
      "Training Results - Epoch: 25, Accuracy: 1.00000, Avg loss: 0.00012\n",
      "Epoch[26], Iter: 901, Loss: 0.00058\n",
      "Epoch[26], Iter: 904, Loss: 0.00008\n",
      "Epoch[26], Iter: 907, Loss: 0.00025\n",
      "Epoch[26], Iter: 910, Loss: 0.00053\n",
      "Epoch[26], Iter: 913, Loss: 0.00002\n",
      "Epoch[26], Iter: 916, Loss: 0.00008\n",
      "Epoch[26], Iter: 919, Loss: 0.00023\n",
      "Epoch[26], Iter: 922, Loss: 0.00052\n",
      "Epoch[26], Iter: 925, Loss: 0.00010\n",
      "Epoch[26], Iter: 928, Loss: 0.00391\n",
      "Epoch[26], Iter: 931, Loss: 0.00057\n",
      "Epoch[26], Iter: 934, Loss: 0.00017\n",
      "Training Results - Epoch: 26, Accuracy: 1.00000, Avg loss: 0.00009\n",
      "Epoch[27], Iter: 937, Loss: 0.00025\n",
      "Epoch[27], Iter: 940, Loss: 0.00080\n",
      "Epoch[27], Iter: 943, Loss: 0.00023\n",
      "Epoch[27], Iter: 946, Loss: 0.00025\n",
      "Epoch[27], Iter: 949, Loss: 0.00097\n",
      "Epoch[27], Iter: 952, Loss: 0.00004\n",
      "Epoch[27], Iter: 955, Loss: 0.00050\n",
      "Epoch[27], Iter: 958, Loss: 0.00019\n",
      "Epoch[27], Iter: 961, Loss: 0.00003\n",
      "Epoch[27], Iter: 964, Loss: 0.00005\n",
      "Epoch[27], Iter: 967, Loss: 0.00020\n",
      "Epoch[27], Iter: 970, Loss: 0.00028\n",
      "Training Results - Epoch: 27, Accuracy: 1.00000, Avg loss: 0.00009\n",
      "Epoch[28], Iter: 973, Loss: 0.00049\n",
      "Epoch[28], Iter: 976, Loss: 0.00032\n",
      "Epoch[28], Iter: 979, Loss: 0.00016\n",
      "Epoch[28], Iter: 982, Loss: 0.00000\n",
      "Epoch[28], Iter: 985, Loss: 0.00106\n",
      "Epoch[28], Iter: 988, Loss: 0.00001\n",
      "Epoch[28], Iter: 991, Loss: 0.00008\n",
      "Epoch[28], Iter: 994, Loss: 0.00001\n",
      "Epoch[28], Iter: 997, Loss: 0.00009\n",
      "Epoch[28], Iter: 1000, Loss: 0.00018\n",
      "Epoch[28], Iter: 1003, Loss: 0.00005\n",
      "Epoch[28], Iter: 1006, Loss: 0.00010\n",
      "Training Results - Epoch: 28, Accuracy: 1.00000, Avg loss: 0.00008\n",
      "Epoch[29], Iter: 1009, Loss: 0.00004\n",
      "Epoch[29], Iter: 1012, Loss: 0.00589\n",
      "Epoch[29], Iter: 1015, Loss: 0.00156\n",
      "Epoch[29], Iter: 1018, Loss: 0.00020\n",
      "Epoch[29], Iter: 1021, Loss: 0.00029\n",
      "Epoch[29], Iter: 1024, Loss: 0.00026\n",
      "Epoch[29], Iter: 1027, Loss: 0.00014\n",
      "Epoch[29], Iter: 1030, Loss: 0.00017\n",
      "Epoch[29], Iter: 1033, Loss: 0.00362\n",
      "Epoch[29], Iter: 1036, Loss: 0.00004\n",
      "Epoch[29], Iter: 1039, Loss: 0.00001\n",
      "Epoch[29], Iter: 1042, Loss: 0.00092\n",
      "Training Results - Epoch: 29, Accuracy: 1.00000, Avg loss: 0.00006\n",
      "Epoch[30], Iter: 1045, Loss: 0.00000\n",
      "Epoch[30], Iter: 1048, Loss: 0.00003\n",
      "Epoch[30], Iter: 1051, Loss: 0.00005\n",
      "Epoch[30], Iter: 1054, Loss: 0.00081\n",
      "Epoch[30], Iter: 1057, Loss: 0.00039\n",
      "Epoch[30], Iter: 1060, Loss: 0.00124\n",
      "Epoch[30], Iter: 1063, Loss: 0.00001\n",
      "Epoch[30], Iter: 1066, Loss: 0.00013\n",
      "Epoch[30], Iter: 1069, Loss: 0.00000\n",
      "Epoch[30], Iter: 1072, Loss: 0.00008\n",
      "Epoch[30], Iter: 1075, Loss: 0.00030\n",
      "Epoch[30], Iter: 1078, Loss: 0.00028\n",
      "Training Results - Epoch: 30, Accuracy: 1.00000, Avg loss: 0.00005\n",
      "Epoch[31], Iter: 1081, Loss: 0.00002\n",
      "Epoch[31], Iter: 1084, Loss: 0.00000\n",
      "Epoch[31], Iter: 1087, Loss: 0.00035\n",
      "Epoch[31], Iter: 1090, Loss: 0.00057\n",
      "Epoch[31], Iter: 1093, Loss: 0.00002\n",
      "Epoch[31], Iter: 1096, Loss: 0.00011\n",
      "Epoch[31], Iter: 1099, Loss: 0.00015\n",
      "Epoch[31], Iter: 1102, Loss: 0.00004\n",
      "Epoch[31], Iter: 1105, Loss: 0.00028\n",
      "Epoch[31], Iter: 1108, Loss: 0.00036\n",
      "Epoch[31], Iter: 1111, Loss: 0.00013\n",
      "Epoch[31], Iter: 1114, Loss: 0.00011\n",
      "Training Results - Epoch: 31, Accuracy: 1.00000, Avg loss: 0.00005\n",
      "Epoch[32], Iter: 1117, Loss: 0.00063\n",
      "Epoch[32], Iter: 1120, Loss: 0.00003\n",
      "Epoch[32], Iter: 1123, Loss: 0.00002\n",
      "Epoch[32], Iter: 1126, Loss: 0.00005\n",
      "Epoch[32], Iter: 1129, Loss: 0.00001\n",
      "Epoch[32], Iter: 1132, Loss: 0.00001\n",
      "Epoch[32], Iter: 1135, Loss: 0.00012\n",
      "Epoch[32], Iter: 1138, Loss: 0.00001\n",
      "Epoch[32], Iter: 1141, Loss: 0.00002\n",
      "Epoch[32], Iter: 1144, Loss: 0.00029\n",
      "Epoch[32], Iter: 1147, Loss: 0.00006\n",
      "Epoch[32], Iter: 1150, Loss: 0.00003\n",
      "Training Results - Epoch: 32, Accuracy: 1.00000, Avg loss: 0.00005\n",
      "Epoch[33], Iter: 1153, Loss: 0.00003\n",
      "Epoch[33], Iter: 1156, Loss: 0.00005\n",
      "Epoch[33], Iter: 1159, Loss: 0.00002\n",
      "Epoch[33], Iter: 1162, Loss: 0.00002\n",
      "Epoch[33], Iter: 1165, Loss: 0.00004\n",
      "Epoch[33], Iter: 1168, Loss: 0.00001\n",
      "Epoch[33], Iter: 1171, Loss: 0.00007\n",
      "Epoch[33], Iter: 1174, Loss: 0.00001\n",
      "Epoch[33], Iter: 1177, Loss: 0.00021\n",
      "Epoch[33], Iter: 1180, Loss: 0.00010\n",
      "Epoch[33], Iter: 1183, Loss: 0.00002\n",
      "Epoch[33], Iter: 1186, Loss: 0.00202\n",
      "Training Results - Epoch: 33, Accuracy: 1.00000, Avg loss: 0.00004\n",
      "Epoch[34], Iter: 1189, Loss: 0.00000\n",
      "Epoch[34], Iter: 1192, Loss: 0.00004\n",
      "Epoch[34], Iter: 1195, Loss: 0.00000\n",
      "Epoch[34], Iter: 1198, Loss: 0.00008\n",
      "Epoch[34], Iter: 1201, Loss: 0.00001\n",
      "Epoch[34], Iter: 1204, Loss: 0.00248\n",
      "Epoch[34], Iter: 1207, Loss: 0.00003\n",
      "Epoch[34], Iter: 1210, Loss: 0.00005\n",
      "Epoch[34], Iter: 1213, Loss: 0.00003\n",
      "Epoch[34], Iter: 1216, Loss: 0.00002\n",
      "Epoch[34], Iter: 1219, Loss: 0.00002\n",
      "Epoch[34], Iter: 1222, Loss: 0.00118\n",
      "Training Results - Epoch: 34, Accuracy: 1.00000, Avg loss: 0.00004\n",
      "Epoch[35], Iter: 1225, Loss: 0.00022\n",
      "Epoch[35], Iter: 1228, Loss: 0.00002\n",
      "Epoch[35], Iter: 1231, Loss: 0.00085\n",
      "Epoch[35], Iter: 1234, Loss: 0.00061\n",
      "Epoch[35], Iter: 1237, Loss: 0.00003\n",
      "Epoch[35], Iter: 1240, Loss: 0.00033\n",
      "Epoch[35], Iter: 1243, Loss: 0.00003\n",
      "Epoch[35], Iter: 1246, Loss: 0.00003\n",
      "Epoch[35], Iter: 1249, Loss: 0.00017\n",
      "Epoch[35], Iter: 1252, Loss: 0.00000\n",
      "Epoch[35], Iter: 1255, Loss: 0.00028\n",
      "Epoch[35], Iter: 1258, Loss: 0.00029\n",
      "Training Results - Epoch: 35, Accuracy: 1.00000, Avg loss: 0.00005\n",
      "Epoch[36], Iter: 1261, Loss: 0.00012\n",
      "Epoch[36], Iter: 1264, Loss: 0.00002\n",
      "Epoch[36], Iter: 1267, Loss: 0.00022\n",
      "Epoch[36], Iter: 1270, Loss: 0.00000\n",
      "Epoch[36], Iter: 1273, Loss: 0.00004\n",
      "Epoch[36], Iter: 1276, Loss: 0.00008\n",
      "Epoch[36], Iter: 1279, Loss: 0.00000\n",
      "Epoch[36], Iter: 1282, Loss: 0.00053\n",
      "Epoch[36], Iter: 1285, Loss: 0.00018\n",
      "Epoch[36], Iter: 1288, Loss: 0.00028\n",
      "Epoch[36], Iter: 1291, Loss: 0.00000\n",
      "Epoch[36], Iter: 1294, Loss: 0.00055\n",
      "Training Results - Epoch: 36, Accuracy: 1.00000, Avg loss: 0.00004\n",
      "Epoch[37], Iter: 1297, Loss: 0.00022\n",
      "Epoch[37], Iter: 1300, Loss: 0.00004\n",
      "Epoch[37], Iter: 1303, Loss: 0.00001\n",
      "Epoch[37], Iter: 1306, Loss: 0.00009\n",
      "Epoch[37], Iter: 1309, Loss: 0.00001\n",
      "Epoch[37], Iter: 1312, Loss: 0.00016\n",
      "Epoch[37], Iter: 1315, Loss: 0.00001\n",
      "Epoch[37], Iter: 1318, Loss: 0.00001\n",
      "Epoch[37], Iter: 1321, Loss: 0.00005\n",
      "Epoch[37], Iter: 1324, Loss: 0.00009\n",
      "Epoch[37], Iter: 1327, Loss: 0.00023\n",
      "Epoch[37], Iter: 1330, Loss: 0.00014\n",
      "Training Results - Epoch: 37, Accuracy: 1.00000, Avg loss: 0.00003\n",
      "Epoch[38], Iter: 1333, Loss: 0.00064\n",
      "Epoch[38], Iter: 1336, Loss: 0.00000\n",
      "Epoch[38], Iter: 1339, Loss: 0.00009\n",
      "Epoch[38], Iter: 1342, Loss: 0.00009\n",
      "Epoch[38], Iter: 1345, Loss: 0.00019\n",
      "Epoch[38], Iter: 1348, Loss: 0.00001\n",
      "Epoch[38], Iter: 1351, Loss: 0.00012\n",
      "Epoch[38], Iter: 1354, Loss: 0.00001\n",
      "Epoch[38], Iter: 1357, Loss: 0.00006\n",
      "Epoch[38], Iter: 1360, Loss: 0.00003\n",
      "Epoch[38], Iter: 1363, Loss: 0.00004\n",
      "Epoch[38], Iter: 1366, Loss: 0.00005\n",
      "Training Results - Epoch: 38, Accuracy: 1.00000, Avg loss: 0.00003\n",
      "Epoch[39], Iter: 1369, Loss: 0.00000\n",
      "Epoch[39], Iter: 1372, Loss: 0.00005\n",
      "Epoch[39], Iter: 1375, Loss: 0.00028\n",
      "Epoch[39], Iter: 1378, Loss: 0.00010\n",
      "Epoch[39], Iter: 1381, Loss: 0.00001\n",
      "Epoch[39], Iter: 1384, Loss: 0.00005\n",
      "Epoch[39], Iter: 1387, Loss: 0.00000\n",
      "Epoch[39], Iter: 1390, Loss: 0.00031\n",
      "Epoch[39], Iter: 1393, Loss: 0.00004\n",
      "Epoch[39], Iter: 1396, Loss: 0.00008\n",
      "Epoch[39], Iter: 1399, Loss: 0.00006\n",
      "Epoch[39], Iter: 1402, Loss: 0.00003\n",
      "Training Results - Epoch: 39, Accuracy: 1.00000, Avg loss: 0.00003\n",
      "Epoch[40], Iter: 1405, Loss: 0.00031\n",
      "Epoch[40], Iter: 1408, Loss: 0.00001\n",
      "Epoch[40], Iter: 1411, Loss: 0.00005\n",
      "Epoch[40], Iter: 1414, Loss: 0.00003\n",
      "Epoch[40], Iter: 1417, Loss: 0.00007\n",
      "Epoch[40], Iter: 1420, Loss: 0.00002\n",
      "Epoch[40], Iter: 1423, Loss: 0.00003\n",
      "Epoch[40], Iter: 1426, Loss: 0.00006\n",
      "Epoch[40], Iter: 1429, Loss: 0.00001\n",
      "Epoch[40], Iter: 1432, Loss: 0.00006\n",
      "Epoch[40], Iter: 1435, Loss: 0.00028\n",
      "Epoch[40], Iter: 1438, Loss: 0.00001\n",
      "Training Results - Epoch: 40, Accuracy: 1.00000, Avg loss: 0.00003\n",
      "Epoch[41], Iter: 1441, Loss: 0.00082\n",
      "Epoch[41], Iter: 1444, Loss: 0.00137\n",
      "Epoch[41], Iter: 1447, Loss: 0.00001\n",
      "Epoch[41], Iter: 1450, Loss: 0.00001\n",
      "Epoch[41], Iter: 1453, Loss: 0.00053\n",
      "Epoch[41], Iter: 1456, Loss: 0.00032\n",
      "Epoch[41], Iter: 1459, Loss: 0.00002\n",
      "Epoch[41], Iter: 1462, Loss: 0.00064\n",
      "Epoch[41], Iter: 1465, Loss: 0.00001\n",
      "Epoch[41], Iter: 1468, Loss: 0.00018\n",
      "Epoch[41], Iter: 1471, Loss: 0.00004\n",
      "Epoch[41], Iter: 1474, Loss: 0.00005\n",
      "Training Results - Epoch: 41, Accuracy: 1.00000, Avg loss: 0.00003\n",
      "Epoch[42], Iter: 1477, Loss: 0.00001\n",
      "Epoch[42], Iter: 1480, Loss: 0.00022\n",
      "Epoch[42], Iter: 1483, Loss: 0.00000\n",
      "Epoch[42], Iter: 1486, Loss: 0.00006\n",
      "Epoch[42], Iter: 1489, Loss: 0.00001\n",
      "Epoch[42], Iter: 1492, Loss: 0.00000\n",
      "Epoch[42], Iter: 1495, Loss: 0.00008\n",
      "Epoch[42], Iter: 1498, Loss: 0.00001\n",
      "Epoch[42], Iter: 1501, Loss: 0.00002\n",
      "Epoch[42], Iter: 1504, Loss: 0.00015\n",
      "Epoch[42], Iter: 1507, Loss: 0.00001\n",
      "Epoch[42], Iter: 1510, Loss: 0.00001\n",
      "Training Results - Epoch: 42, Accuracy: 1.00000, Avg loss: 0.00002\n",
      "Epoch[43], Iter: 1513, Loss: 0.00000\n",
      "Epoch[43], Iter: 1516, Loss: 0.00014\n",
      "Epoch[43], Iter: 1519, Loss: 0.00014\n",
      "Epoch[43], Iter: 1522, Loss: 0.00010\n",
      "Epoch[43], Iter: 1525, Loss: 0.00003\n",
      "Epoch[43], Iter: 1528, Loss: 0.00002\n",
      "Epoch[43], Iter: 1531, Loss: 0.00006\n",
      "Epoch[43], Iter: 1534, Loss: 0.00002\n",
      "Epoch[43], Iter: 1537, Loss: 0.00025\n",
      "Epoch[43], Iter: 1540, Loss: 0.00001\n",
      "Epoch[43], Iter: 1543, Loss: 0.00013\n",
      "Epoch[43], Iter: 1546, Loss: 0.00017\n",
      "Training Results - Epoch: 43, Accuracy: 1.00000, Avg loss: 0.00002\n",
      "Epoch[44], Iter: 1549, Loss: 0.00001\n",
      "Epoch[44], Iter: 1552, Loss: 0.00004\n",
      "Epoch[44], Iter: 1555, Loss: 0.00086\n",
      "Epoch[44], Iter: 1558, Loss: 0.00024\n",
      "Epoch[44], Iter: 1561, Loss: 0.00004\n",
      "Epoch[44], Iter: 1564, Loss: 0.00031\n",
      "Epoch[44], Iter: 1567, Loss: 0.00000\n",
      "Epoch[44], Iter: 1570, Loss: 0.00000\n",
      "Epoch[44], Iter: 1573, Loss: 0.00015\n",
      "Epoch[44], Iter: 1576, Loss: 0.00081\n",
      "Epoch[44], Iter: 1579, Loss: 0.00026\n",
      "Epoch[44], Iter: 1582, Loss: 0.00003\n",
      "Training Results - Epoch: 44, Accuracy: 1.00000, Avg loss: 0.00002\n",
      "Epoch[45], Iter: 1585, Loss: 0.00006\n",
      "Epoch[45], Iter: 1588, Loss: 0.00004\n",
      "Epoch[45], Iter: 1591, Loss: 0.00001\n",
      "Epoch[45], Iter: 1594, Loss: 0.00005\n",
      "Epoch[45], Iter: 1597, Loss: 0.00012\n",
      "Epoch[45], Iter: 1600, Loss: 0.00003\n",
      "Epoch[45], Iter: 1603, Loss: 0.00002\n",
      "Epoch[45], Iter: 1606, Loss: 0.00000\n",
      "Epoch[45], Iter: 1609, Loss: 0.00002\n",
      "Epoch[45], Iter: 1612, Loss: 0.00042\n",
      "Epoch[45], Iter: 1615, Loss: 0.00000\n",
      "Epoch[45], Iter: 1618, Loss: 0.00007\n",
      "Training Results - Epoch: 45, Accuracy: 1.00000, Avg loss: 0.00002\n",
      "Epoch[46], Iter: 1621, Loss: 0.00007\n",
      "Epoch[46], Iter: 1624, Loss: 0.00011\n",
      "Epoch[46], Iter: 1627, Loss: 0.00001\n",
      "Epoch[46], Iter: 1630, Loss: 0.00010\n",
      "Epoch[46], Iter: 1633, Loss: 0.00006\n",
      "Epoch[46], Iter: 1636, Loss: 0.00014\n",
      "Epoch[46], Iter: 1639, Loss: 0.00039\n",
      "Epoch[46], Iter: 1642, Loss: 0.00005\n",
      "Epoch[46], Iter: 1645, Loss: 0.00024\n",
      "Epoch[46], Iter: 1648, Loss: 0.00002\n",
      "Epoch[46], Iter: 1651, Loss: 0.00006\n",
      "Epoch[46], Iter: 1654, Loss: 0.00008\n",
      "Training Results - Epoch: 46, Accuracy: 1.00000, Avg loss: 0.00002\n",
      "Epoch[47], Iter: 1657, Loss: 0.00003\n",
      "Epoch[47], Iter: 1660, Loss: 0.00027\n",
      "Epoch[47], Iter: 1663, Loss: 0.00002\n",
      "Epoch[47], Iter: 1666, Loss: 0.00007\n",
      "Epoch[47], Iter: 1669, Loss: 0.00000\n",
      "Epoch[47], Iter: 1672, Loss: 0.00002\n",
      "Epoch[47], Iter: 1675, Loss: 0.00001\n",
      "Epoch[47], Iter: 1678, Loss: 0.00000\n",
      "Epoch[47], Iter: 1681, Loss: 0.00041\n",
      "Epoch[47], Iter: 1684, Loss: 0.00015\n",
      "Epoch[47], Iter: 1687, Loss: 0.00006\n",
      "Epoch[47], Iter: 1690, Loss: 0.00002\n",
      "Training Results - Epoch: 47, Accuracy: 1.00000, Avg loss: 0.00002\n",
      "Epoch[48], Iter: 1693, Loss: 0.00001\n",
      "Epoch[48], Iter: 1696, Loss: 0.00003\n",
      "Epoch[48], Iter: 1699, Loss: 0.00014\n",
      "Epoch[48], Iter: 1702, Loss: 0.00003\n",
      "Epoch[48], Iter: 1705, Loss: 0.00002\n",
      "Epoch[48], Iter: 1708, Loss: 0.00002\n",
      "Epoch[48], Iter: 1711, Loss: 0.00036\n",
      "Epoch[48], Iter: 1714, Loss: 0.00002\n",
      "Epoch[48], Iter: 1717, Loss: 0.00028\n",
      "Epoch[48], Iter: 1720, Loss: 0.00001\n",
      "Epoch[48], Iter: 1723, Loss: 0.00000\n",
      "Epoch[48], Iter: 1726, Loss: 0.00007\n",
      "Training Results - Epoch: 48, Accuracy: 1.00000, Avg loss: 0.00002\n",
      "Epoch[49], Iter: 1729, Loss: 0.00110\n",
      "Epoch[49], Iter: 1732, Loss: 0.00001\n",
      "Epoch[49], Iter: 1735, Loss: 0.00003\n",
      "Epoch[49], Iter: 1738, Loss: 0.00654\n",
      "Epoch[49], Iter: 1741, Loss: 0.00002\n",
      "Epoch[49], Iter: 1744, Loss: 0.00000\n",
      "Epoch[49], Iter: 1747, Loss: 0.00020\n",
      "Epoch[49], Iter: 1750, Loss: 0.00001\n",
      "Epoch[49], Iter: 1753, Loss: 0.00002\n",
      "Epoch[49], Iter: 1756, Loss: 0.00000\n",
      "Epoch[49], Iter: 1759, Loss: 0.00000\n",
      "Epoch[49], Iter: 1762, Loss: 0.00005\n",
      "Training Results - Epoch: 49, Accuracy: 1.00000, Avg loss: 0.00004\n",
      "Epoch[50], Iter: 1765, Loss: 0.00000\n",
      "Epoch[50], Iter: 1768, Loss: 0.00031\n",
      "Epoch[50], Iter: 1771, Loss: 0.00004\n",
      "Epoch[50], Iter: 1774, Loss: 0.00008\n",
      "Epoch[50], Iter: 1777, Loss: 0.00185\n",
      "Epoch[50], Iter: 1780, Loss: 0.00023\n",
      "Epoch[50], Iter: 1783, Loss: 0.00302\n",
      "Epoch[50], Iter: 1786, Loss: 0.00002\n",
      "Epoch[50], Iter: 1789, Loss: 0.00008\n",
      "Epoch[50], Iter: 1792, Loss: 0.00001\n",
      "Epoch[50], Iter: 1795, Loss: 0.00004\n",
      "Epoch[50], Iter: 1798, Loss: 0.00018\n",
      "Training Results - Epoch: 50, Accuracy: 1.00000, Avg loss: 0.00002\n",
      "Epoch[51], Iter: 1801, Loss: 0.00047\n",
      "Epoch[51], Iter: 1804, Loss: 0.00044\n",
      "Epoch[51], Iter: 1807, Loss: 0.00015\n",
      "Epoch[51], Iter: 1810, Loss: 0.00001\n",
      "Epoch[51], Iter: 1813, Loss: 0.00003\n",
      "Epoch[51], Iter: 1816, Loss: 0.00003\n",
      "Epoch[51], Iter: 1819, Loss: 0.00000\n",
      "Epoch[51], Iter: 1822, Loss: 0.00000\n",
      "Epoch[51], Iter: 1825, Loss: 0.00002\n",
      "Epoch[51], Iter: 1828, Loss: 0.00000\n",
      "Epoch[51], Iter: 1831, Loss: 0.00001\n",
      "Epoch[51], Iter: 1834, Loss: 0.00000\n",
      "Training Results - Epoch: 51, Accuracy: 1.00000, Avg loss: 0.00001\n",
      "Epoch[52], Iter: 1837, Loss: 0.00000\n",
      "Epoch[52], Iter: 1840, Loss: 0.00001\n",
      "Epoch[52], Iter: 1843, Loss: 0.00008\n",
      "Epoch[52], Iter: 1846, Loss: 0.00012\n",
      "Epoch[52], Iter: 1849, Loss: 0.00020\n",
      "Epoch[52], Iter: 1852, Loss: 0.00009\n",
      "Epoch[52], Iter: 1855, Loss: 0.00001\n",
      "Epoch[52], Iter: 1858, Loss: 0.00001\n",
      "Epoch[52], Iter: 1861, Loss: 0.00001\n",
      "Epoch[52], Iter: 1864, Loss: 0.00006\n",
      "Epoch[52], Iter: 1867, Loss: 0.00000\n",
      "Epoch[52], Iter: 1870, Loss: 0.00005\n",
      "Training Results - Epoch: 52, Accuracy: 1.00000, Avg loss: 0.00001\n",
      "Epoch[53], Iter: 1873, Loss: 0.00002\n",
      "Epoch[53], Iter: 1876, Loss: 0.00001\n",
      "Epoch[53], Iter: 1879, Loss: 0.00052\n",
      "Epoch[53], Iter: 1882, Loss: 0.00036\n",
      "Epoch[53], Iter: 1885, Loss: 0.00000\n",
      "Epoch[53], Iter: 1888, Loss: 0.00000\n",
      "Epoch[53], Iter: 1891, Loss: 0.00003\n",
      "Epoch[53], Iter: 1894, Loss: 0.00001\n",
      "Epoch[53], Iter: 1897, Loss: 0.00001\n",
      "Epoch[53], Iter: 1900, Loss: 0.00001\n",
      "Epoch[53], Iter: 1903, Loss: 0.00002\n",
      "Epoch[53], Iter: 1906, Loss: 0.00004\n",
      "Training Results - Epoch: 53, Accuracy: 1.00000, Avg loss: 0.00001\n",
      "Epoch[54], Iter: 1909, Loss: 0.00032\n",
      "Epoch[54], Iter: 1912, Loss: 0.00001\n",
      "Epoch[54], Iter: 1915, Loss: 0.00000\n",
      "Epoch[54], Iter: 1918, Loss: 0.00000\n",
      "Epoch[54], Iter: 1921, Loss: 0.00023\n",
      "Epoch[54], Iter: 1924, Loss: 0.00002\n",
      "Epoch[54], Iter: 1927, Loss: 0.00006\n",
      "Epoch[54], Iter: 1930, Loss: 0.00000\n",
      "Epoch[54], Iter: 1933, Loss: 0.00000\n",
      "Epoch[54], Iter: 1936, Loss: 0.00004\n",
      "Epoch[54], Iter: 1939, Loss: 0.00000\n",
      "Epoch[54], Iter: 1942, Loss: 0.00001\n",
      "Training Results - Epoch: 54, Accuracy: 1.00000, Avg loss: 0.00001\n",
      "Epoch[55], Iter: 1945, Loss: 0.00001\n",
      "Epoch[55], Iter: 1948, Loss: 0.00007\n",
      "Epoch[55], Iter: 1951, Loss: 0.00001\n",
      "Epoch[55], Iter: 1954, Loss: 0.00001\n",
      "Epoch[55], Iter: 1957, Loss: 0.00014\n",
      "Epoch[55], Iter: 1960, Loss: 0.00000\n",
      "Epoch[55], Iter: 1963, Loss: 0.00002\n",
      "Epoch[55], Iter: 1966, Loss: 0.00001\n",
      "Epoch[55], Iter: 1969, Loss: 0.00002\n",
      "Epoch[55], Iter: 1972, Loss: 0.00006\n",
      "Epoch[55], Iter: 1975, Loss: 0.00010\n",
      "Epoch[55], Iter: 1978, Loss: 0.00032\n",
      "Training Results - Epoch: 55, Accuracy: 1.00000, Avg loss: 0.00001\n",
      "Epoch[56], Iter: 1981, Loss: 0.00002\n",
      "Epoch[56], Iter: 1984, Loss: 0.00020\n",
      "Epoch[56], Iter: 1987, Loss: 0.00002\n",
      "Epoch[56], Iter: 1990, Loss: 0.00002\n",
      "Epoch[56], Iter: 1993, Loss: 0.00004\n",
      "Epoch[56], Iter: 1996, Loss: 0.00002\n",
      "Epoch[56], Iter: 1999, Loss: 0.00000\n",
      "Epoch[56], Iter: 2002, Loss: 0.00000\n",
      "Epoch[56], Iter: 2005, Loss: 0.00000\n",
      "Epoch[56], Iter: 2008, Loss: 0.00003\n",
      "Epoch[56], Iter: 2011, Loss: 0.00004\n",
      "Epoch[56], Iter: 2014, Loss: 0.00002\n",
      "Training Results - Epoch: 56, Accuracy: 1.00000, Avg loss: 0.00001\n",
      "Epoch[57], Iter: 2017, Loss: 0.00022\n",
      "Epoch[57], Iter: 2020, Loss: 0.00001\n",
      "Epoch[57], Iter: 2023, Loss: 0.00002\n",
      "Epoch[57], Iter: 2026, Loss: 0.00003\n",
      "Epoch[57], Iter: 2029, Loss: 0.00003\n",
      "Epoch[57], Iter: 2032, Loss: 0.00002\n",
      "Epoch[57], Iter: 2035, Loss: 0.00002\n",
      "Epoch[57], Iter: 2038, Loss: 0.00002\n",
      "Epoch[57], Iter: 2041, Loss: 0.00024\n",
      "Epoch[57], Iter: 2044, Loss: 0.00003\n",
      "Epoch[57], Iter: 2047, Loss: 0.00056\n",
      "Epoch[57], Iter: 2050, Loss: 0.00007\n",
      "Training Results - Epoch: 57, Accuracy: 1.00000, Avg loss: 0.00001\n",
      "Epoch[58], Iter: 2053, Loss: 0.00083\n",
      "Epoch[58], Iter: 2056, Loss: 0.00003\n",
      "Epoch[58], Iter: 2059, Loss: 0.00012\n",
      "Epoch[58], Iter: 2062, Loss: 0.00001\n",
      "Epoch[58], Iter: 2065, Loss: 0.00005\n",
      "Epoch[58], Iter: 2068, Loss: 0.00002\n",
      "Epoch[58], Iter: 2071, Loss: 0.00017\n",
      "Epoch[58], Iter: 2074, Loss: 0.00000\n",
      "Epoch[58], Iter: 2077, Loss: 0.00000\n",
      "Epoch[58], Iter: 2080, Loss: 0.00073\n",
      "Epoch[58], Iter: 2083, Loss: 0.00264\n",
      "Epoch[58], Iter: 2086, Loss: 0.00007\n",
      "Training Results - Epoch: 58, Accuracy: 1.00000, Avg loss: 0.00001\n",
      "Epoch[59], Iter: 2089, Loss: 0.00008\n",
      "Epoch[59], Iter: 2092, Loss: 0.00006\n",
      "Epoch[59], Iter: 2095, Loss: 0.00000\n",
      "Epoch[59], Iter: 2098, Loss: 0.00003\n",
      "Epoch[59], Iter: 2101, Loss: 0.00034\n",
      "Epoch[59], Iter: 2104, Loss: 0.00000\n",
      "Epoch[59], Iter: 2107, Loss: 0.00001\n",
      "Epoch[59], Iter: 2110, Loss: 0.00012\n",
      "Epoch[59], Iter: 2113, Loss: 0.00000\n",
      "Epoch[59], Iter: 2116, Loss: 0.00002\n",
      "Epoch[59], Iter: 2119, Loss: 0.00003\n",
      "Epoch[59], Iter: 2122, Loss: 0.00040\n",
      "Training Results - Epoch: 59, Accuracy: 1.00000, Avg loss: 0.00001\n",
      "Epoch[60], Iter: 2125, Loss: 0.00012\n",
      "Epoch[60], Iter: 2128, Loss: 0.00003\n",
      "Epoch[60], Iter: 2131, Loss: 0.00000\n",
      "Epoch[60], Iter: 2134, Loss: 0.00002\n",
      "Epoch[60], Iter: 2137, Loss: 0.00000\n",
      "Epoch[60], Iter: 2140, Loss: 0.00009\n",
      "Epoch[60], Iter: 2143, Loss: 0.00001\n",
      "Epoch[60], Iter: 2146, Loss: 0.00002\n",
      "Epoch[60], Iter: 2149, Loss: 0.00000\n",
      "Epoch[60], Iter: 2152, Loss: 0.00000\n",
      "Epoch[60], Iter: 2155, Loss: 0.00029\n",
      "Epoch[60], Iter: 2158, Loss: 0.00003\n",
      "Training Results - Epoch: 60, Accuracy: 1.00000, Avg loss: 0.00001\n",
      "Epoch[61], Iter: 2161, Loss: 0.00000\n",
      "Epoch[61], Iter: 2164, Loss: 0.00039\n",
      "Epoch[61], Iter: 2167, Loss: 0.00001\n",
      "Epoch[61], Iter: 2170, Loss: 0.00000\n",
      "Epoch[61], Iter: 2173, Loss: 0.00000\n",
      "Epoch[61], Iter: 2176, Loss: 0.00001\n",
      "Epoch[61], Iter: 2179, Loss: 0.00000\n",
      "Epoch[61], Iter: 2182, Loss: 0.00137\n",
      "Epoch[61], Iter: 2185, Loss: 0.00007\n",
      "Epoch[61], Iter: 2188, Loss: 0.00002\n",
      "Epoch[61], Iter: 2191, Loss: 0.00003\n",
      "Epoch[61], Iter: 2194, Loss: 0.00000\n",
      "Training Results - Epoch: 61, Accuracy: 1.00000, Avg loss: 0.00001\n",
      "Epoch[62], Iter: 2197, Loss: 0.00018\n",
      "Epoch[62], Iter: 2200, Loss: 0.00004\n",
      "Epoch[62], Iter: 2203, Loss: 0.00010\n",
      "Epoch[62], Iter: 2206, Loss: 0.00000\n",
      "Epoch[62], Iter: 2209, Loss: 0.00009\n",
      "Epoch[62], Iter: 2212, Loss: 0.00000\n",
      "Epoch[62], Iter: 2215, Loss: 0.00011\n",
      "Epoch[62], Iter: 2218, Loss: 0.00002\n",
      "Epoch[62], Iter: 2221, Loss: 0.00001\n",
      "Epoch[62], Iter: 2224, Loss: 0.00001\n",
      "Epoch[62], Iter: 2227, Loss: 0.00004\n",
      "Epoch[62], Iter: 2230, Loss: 0.00030\n",
      "Training Results - Epoch: 62, Accuracy: 1.00000, Avg loss: 0.00001\n",
      "Epoch[63], Iter: 2233, Loss: 0.00000\n",
      "Epoch[63], Iter: 2236, Loss: 0.00082\n",
      "Epoch[63], Iter: 2239, Loss: 0.00011\n",
      "Epoch[63], Iter: 2242, Loss: 0.00000\n",
      "Epoch[63], Iter: 2245, Loss: 0.00015\n",
      "Epoch[63], Iter: 2248, Loss: 0.00000\n",
      "Epoch[63], Iter: 2251, Loss: 0.00000\n",
      "Epoch[63], Iter: 2254, Loss: 0.00004\n",
      "Epoch[63], Iter: 2257, Loss: 0.00001\n",
      "Epoch[63], Iter: 2260, Loss: 0.00011\n",
      "Epoch[63], Iter: 2263, Loss: 0.00010\n",
      "Epoch[63], Iter: 2266, Loss: 0.00014\n",
      "Training Results - Epoch: 63, Accuracy: 1.00000, Avg loss: 0.00001\n",
      "Epoch[64], Iter: 2269, Loss: 0.00001\n",
      "Epoch[64], Iter: 2272, Loss: 0.00002\n",
      "Epoch[64], Iter: 2275, Loss: 0.00003\n",
      "Epoch[64], Iter: 2278, Loss: 0.00017\n",
      "Epoch[64], Iter: 2281, Loss: 0.00011\n",
      "Epoch[64], Iter: 2284, Loss: 0.00001\n",
      "Epoch[64], Iter: 2287, Loss: 0.00009\n",
      "Epoch[64], Iter: 2290, Loss: 0.00002\n",
      "Epoch[64], Iter: 2293, Loss: 0.00005\n",
      "Epoch[64], Iter: 2296, Loss: 0.00002\n",
      "Epoch[64], Iter: 2299, Loss: 0.00000\n",
      "Epoch[64], Iter: 2302, Loss: 0.00001\n",
      "Training Results - Epoch: 64, Accuracy: 1.00000, Avg loss: 0.00001\n",
      "Epoch[65], Iter: 2305, Loss: 0.00002\n",
      "Epoch[65], Iter: 2308, Loss: 0.00017\n",
      "Epoch[65], Iter: 2311, Loss: 0.00001\n",
      "Epoch[65], Iter: 2314, Loss: 0.00027\n",
      "Epoch[65], Iter: 2317, Loss: 0.00001\n",
      "Epoch[65], Iter: 2320, Loss: 0.00000\n",
      "Epoch[65], Iter: 2323, Loss: 0.00001\n",
      "Epoch[65], Iter: 2326, Loss: 0.00000\n",
      "Epoch[65], Iter: 2329, Loss: 0.00001\n",
      "Epoch[65], Iter: 2332, Loss: 0.00022\n",
      "Epoch[65], Iter: 2335, Loss: 0.00000\n",
      "Epoch[65], Iter: 2338, Loss: 0.00000\n",
      "Training Results - Epoch: 65, Accuracy: 1.00000, Avg loss: 0.00001\n",
      "Epoch[66], Iter: 2341, Loss: 0.00003\n",
      "Epoch[66], Iter: 2344, Loss: 0.00001\n",
      "Epoch[66], Iter: 2347, Loss: 0.00001\n",
      "Epoch[66], Iter: 2350, Loss: 0.00007\n",
      "Epoch[66], Iter: 2353, Loss: 0.00004\n",
      "Epoch[66], Iter: 2356, Loss: 0.00008\n",
      "Epoch[66], Iter: 2359, Loss: 0.00000\n",
      "Epoch[66], Iter: 2362, Loss: 0.00006\n",
      "Epoch[66], Iter: 2365, Loss: 0.00000\n",
      "Epoch[66], Iter: 2368, Loss: 0.00004\n",
      "Epoch[66], Iter: 2371, Loss: 0.00000\n",
      "Epoch[66], Iter: 2374, Loss: 0.00012\n",
      "Training Results - Epoch: 66, Accuracy: 1.00000, Avg loss: 0.00001\n",
      "Epoch[67], Iter: 2377, Loss: 0.00001\n",
      "Epoch[67], Iter: 2380, Loss: 0.00001\n",
      "Epoch[67], Iter: 2383, Loss: 0.00006\n",
      "Epoch[67], Iter: 2386, Loss: 0.00000\n",
      "Epoch[67], Iter: 2389, Loss: 0.00005\n",
      "Epoch[67], Iter: 2392, Loss: 0.00005\n",
      "Epoch[67], Iter: 2395, Loss: 0.00005\n",
      "Epoch[67], Iter: 2398, Loss: 0.00003\n",
      "Epoch[67], Iter: 2401, Loss: 0.00001\n",
      "Epoch[67], Iter: 2404, Loss: 0.00021\n",
      "Epoch[67], Iter: 2407, Loss: 0.00008\n",
      "Epoch[67], Iter: 2410, Loss: 0.00005\n",
      "Training Results - Epoch: 67, Accuracy: 1.00000, Avg loss: 0.00001\n",
      "Epoch[68], Iter: 2413, Loss: 0.00001\n",
      "Epoch[68], Iter: 2416, Loss: 0.00001\n",
      "Epoch[68], Iter: 2419, Loss: 0.00000\n",
      "Epoch[68], Iter: 2422, Loss: 0.00001\n",
      "Epoch[68], Iter: 2425, Loss: 0.00002\n",
      "Epoch[68], Iter: 2428, Loss: 0.00011\n",
      "Epoch[68], Iter: 2431, Loss: 0.00004\n",
      "Epoch[68], Iter: 2434, Loss: 0.00000\n",
      "Epoch[68], Iter: 2437, Loss: 0.00002\n",
      "Epoch[68], Iter: 2440, Loss: 0.00000\n",
      "Epoch[68], Iter: 2443, Loss: 0.00001\n",
      "Epoch[68], Iter: 2446, Loss: 0.00002\n",
      "Training Results - Epoch: 68, Accuracy: 1.00000, Avg loss: 0.00001\n",
      "Epoch[69], Iter: 2449, Loss: 0.00000\n",
      "Epoch[69], Iter: 2452, Loss: 0.00000\n",
      "Epoch[69], Iter: 2455, Loss: 0.00007\n",
      "Epoch[69], Iter: 2458, Loss: 0.00001\n",
      "Epoch[69], Iter: 2461, Loss: 0.00005\n",
      "Epoch[69], Iter: 2464, Loss: 0.00000\n",
      "Epoch[69], Iter: 2467, Loss: 0.00003\n",
      "Epoch[69], Iter: 2470, Loss: 0.00000\n",
      "Epoch[69], Iter: 2473, Loss: 0.00005\n",
      "Epoch[69], Iter: 2476, Loss: 0.00000\n",
      "Epoch[69], Iter: 2479, Loss: 0.00003\n",
      "Epoch[69], Iter: 2482, Loss: 0.00000\n",
      "Training Results - Epoch: 69, Accuracy: 1.00000, Avg loss: 0.00001\n",
      "Epoch[70], Iter: 2485, Loss: 0.00000\n",
      "Epoch[70], Iter: 2488, Loss: 0.00006\n",
      "Epoch[70], Iter: 2491, Loss: 0.00000\n",
      "Epoch[70], Iter: 2494, Loss: 0.00001\n",
      "Epoch[70], Iter: 2497, Loss: 0.00003\n",
      "Epoch[70], Iter: 2500, Loss: 0.00000\n",
      "Epoch[70], Iter: 2503, Loss: 0.00125\n",
      "Epoch[70], Iter: 2506, Loss: 0.00000\n",
      "Epoch[70], Iter: 2509, Loss: 0.00000\n",
      "Epoch[70], Iter: 2512, Loss: 0.00000\n",
      "Epoch[70], Iter: 2515, Loss: 0.00000\n",
      "Epoch[70], Iter: 2518, Loss: 0.00003\n",
      "Training Results - Epoch: 70, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[71], Iter: 2521, Loss: 0.00000\n",
      "Epoch[71], Iter: 2524, Loss: 0.00004\n",
      "Epoch[71], Iter: 2527, Loss: 0.00000\n",
      "Epoch[71], Iter: 2530, Loss: 0.00001\n",
      "Epoch[71], Iter: 2533, Loss: 0.00000\n",
      "Epoch[71], Iter: 2536, Loss: 0.00001\n",
      "Epoch[71], Iter: 2539, Loss: 0.00000\n",
      "Epoch[71], Iter: 2542, Loss: 0.00004\n",
      "Epoch[71], Iter: 2545, Loss: 0.00000\n",
      "Epoch[71], Iter: 2548, Loss: 0.00000\n",
      "Epoch[71], Iter: 2551, Loss: 0.00001\n",
      "Epoch[71], Iter: 2554, Loss: 0.00002\n",
      "Training Results - Epoch: 71, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[72], Iter: 2557, Loss: 0.00001\n",
      "Epoch[72], Iter: 2560, Loss: 0.00002\n",
      "Epoch[72], Iter: 2563, Loss: 0.00001\n",
      "Epoch[72], Iter: 2566, Loss: 0.00001\n",
      "Epoch[72], Iter: 2569, Loss: 0.00001\n",
      "Epoch[72], Iter: 2572, Loss: 0.00016\n",
      "Epoch[72], Iter: 2575, Loss: 0.00001\n",
      "Epoch[72], Iter: 2578, Loss: 0.00002\n",
      "Epoch[72], Iter: 2581, Loss: 0.00002\n",
      "Epoch[72], Iter: 2584, Loss: 0.00001\n",
      "Epoch[72], Iter: 2587, Loss: 0.00000\n",
      "Epoch[72], Iter: 2590, Loss: 0.00000\n",
      "Training Results - Epoch: 72, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[73], Iter: 2593, Loss: 0.00001\n",
      "Epoch[73], Iter: 2596, Loss: 0.00001\n",
      "Epoch[73], Iter: 2599, Loss: 0.00001\n",
      "Epoch[73], Iter: 2602, Loss: 0.00000\n",
      "Epoch[73], Iter: 2605, Loss: 0.00000\n",
      "Epoch[73], Iter: 2608, Loss: 0.00002\n",
      "Epoch[73], Iter: 2611, Loss: 0.00001\n",
      "Epoch[73], Iter: 2614, Loss: 0.00001\n",
      "Epoch[73], Iter: 2617, Loss: 0.00002\n",
      "Epoch[73], Iter: 2620, Loss: 0.00000\n",
      "Epoch[73], Iter: 2623, Loss: 0.00001\n",
      "Epoch[73], Iter: 2626, Loss: 0.00001\n",
      "Training Results - Epoch: 73, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[74], Iter: 2629, Loss: 0.00000\n",
      "Epoch[74], Iter: 2632, Loss: 0.00000\n",
      "Epoch[74], Iter: 2635, Loss: 0.00002\n",
      "Epoch[74], Iter: 2638, Loss: 0.00007\n",
      "Epoch[74], Iter: 2641, Loss: 0.00001\n",
      "Epoch[74], Iter: 2644, Loss: 0.00001\n",
      "Epoch[74], Iter: 2647, Loss: 0.00000\n",
      "Epoch[74], Iter: 2650, Loss: 0.00000\n",
      "Epoch[74], Iter: 2653, Loss: 0.00006\n",
      "Epoch[74], Iter: 2656, Loss: 0.00000\n",
      "Epoch[74], Iter: 2659, Loss: 0.00002\n",
      "Epoch[74], Iter: 2662, Loss: 0.00003\n",
      "Training Results - Epoch: 74, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[75], Iter: 2665, Loss: 0.00000\n",
      "Epoch[75], Iter: 2668, Loss: 0.00001\n",
      "Epoch[75], Iter: 2671, Loss: 0.00000\n",
      "Epoch[75], Iter: 2674, Loss: 0.00000\n",
      "Epoch[75], Iter: 2677, Loss: 0.00001\n",
      "Epoch[75], Iter: 2680, Loss: 0.00002\n",
      "Epoch[75], Iter: 2683, Loss: 0.00000\n",
      "Epoch[75], Iter: 2686, Loss: 0.00001\n",
      "Epoch[75], Iter: 2689, Loss: 0.00001\n",
      "Epoch[75], Iter: 2692, Loss: 0.00001\n",
      "Epoch[75], Iter: 2695, Loss: 0.00001\n",
      "Epoch[75], Iter: 2698, Loss: 0.00002\n",
      "Training Results - Epoch: 75, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[76], Iter: 2701, Loss: 0.00000\n",
      "Epoch[76], Iter: 2704, Loss: 0.00001\n",
      "Epoch[76], Iter: 2707, Loss: 0.00000\n",
      "Epoch[76], Iter: 2710, Loss: 0.00007\n",
      "Epoch[76], Iter: 2713, Loss: 0.00000\n",
      "Epoch[76], Iter: 2716, Loss: 0.00005\n",
      "Epoch[76], Iter: 2719, Loss: 0.00003\n",
      "Epoch[76], Iter: 2722, Loss: 0.00000\n",
      "Epoch[76], Iter: 2725, Loss: 0.00002\n",
      "Epoch[76], Iter: 2728, Loss: 0.00002\n",
      "Epoch[76], Iter: 2731, Loss: 0.00000\n",
      "Epoch[76], Iter: 2734, Loss: 0.00000\n",
      "Training Results - Epoch: 76, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[77], Iter: 2737, Loss: 0.00000\n",
      "Epoch[77], Iter: 2740, Loss: 0.00002\n",
      "Epoch[77], Iter: 2743, Loss: 0.00000\n",
      "Epoch[77], Iter: 2746, Loss: 0.00013\n",
      "Epoch[77], Iter: 2749, Loss: 0.00000\n",
      "Epoch[77], Iter: 2752, Loss: 0.00073\n",
      "Epoch[77], Iter: 2755, Loss: 0.00000\n",
      "Epoch[77], Iter: 2758, Loss: 0.00004\n",
      "Epoch[77], Iter: 2761, Loss: 0.00000\n",
      "Epoch[77], Iter: 2764, Loss: 0.00000\n",
      "Epoch[77], Iter: 2767, Loss: 0.00001\n",
      "Epoch[77], Iter: 2770, Loss: 0.00001\n",
      "Training Results - Epoch: 77, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[78], Iter: 2773, Loss: 0.00000\n",
      "Epoch[78], Iter: 2776, Loss: 0.00000\n",
      "Epoch[78], Iter: 2779, Loss: 0.00001\n",
      "Epoch[78], Iter: 2782, Loss: 0.00003\n",
      "Epoch[78], Iter: 2785, Loss: 0.00000\n",
      "Epoch[78], Iter: 2788, Loss: 0.00001\n",
      "Epoch[78], Iter: 2791, Loss: 0.00001\n",
      "Epoch[78], Iter: 2794, Loss: 0.00000\n",
      "Epoch[78], Iter: 2797, Loss: 0.00001\n",
      "Epoch[78], Iter: 2800, Loss: 0.00004\n",
      "Epoch[78], Iter: 2803, Loss: 0.00002\n",
      "Epoch[78], Iter: 2806, Loss: 0.00003\n",
      "Training Results - Epoch: 78, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[79], Iter: 2809, Loss: 0.00001\n",
      "Epoch[79], Iter: 2812, Loss: 0.00004\n",
      "Epoch[79], Iter: 2815, Loss: 0.00003\n",
      "Epoch[79], Iter: 2818, Loss: 0.00011\n",
      "Epoch[79], Iter: 2821, Loss: 0.00000\n",
      "Epoch[79], Iter: 2824, Loss: 0.00000\n",
      "Epoch[79], Iter: 2827, Loss: 0.00000\n",
      "Epoch[79], Iter: 2830, Loss: 0.00000\n",
      "Epoch[79], Iter: 2833, Loss: 0.00001\n",
      "Epoch[79], Iter: 2836, Loss: 0.00001\n",
      "Epoch[79], Iter: 2839, Loss: 0.00001\n",
      "Epoch[79], Iter: 2842, Loss: 0.00003\n",
      "Training Results - Epoch: 79, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[80], Iter: 2845, Loss: 0.00000\n",
      "Epoch[80], Iter: 2848, Loss: 0.00000\n",
      "Epoch[80], Iter: 2851, Loss: 0.00000\n",
      "Epoch[80], Iter: 2854, Loss: 0.00000\n",
      "Epoch[80], Iter: 2857, Loss: 0.00000\n",
      "Epoch[80], Iter: 2860, Loss: 0.00070\n",
      "Epoch[80], Iter: 2863, Loss: 0.00001\n",
      "Epoch[80], Iter: 2866, Loss: 0.00000\n",
      "Epoch[80], Iter: 2869, Loss: 0.00000\n",
      "Epoch[80], Iter: 2872, Loss: 0.00001\n",
      "Epoch[80], Iter: 2875, Loss: 0.00000\n",
      "Epoch[80], Iter: 2878, Loss: 0.00000\n",
      "Training Results - Epoch: 80, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[81], Iter: 2881, Loss: 0.00001\n",
      "Epoch[81], Iter: 2884, Loss: 0.00003\n",
      "Epoch[81], Iter: 2887, Loss: 0.00006\n",
      "Epoch[81], Iter: 2890, Loss: 0.00000\n",
      "Epoch[81], Iter: 2893, Loss: 0.00000\n",
      "Epoch[81], Iter: 2896, Loss: 0.00003\n",
      "Epoch[81], Iter: 2899, Loss: 0.00001\n",
      "Epoch[81], Iter: 2902, Loss: 0.00003\n",
      "Epoch[81], Iter: 2905, Loss: 0.00015\n",
      "Epoch[81], Iter: 2908, Loss: 0.00000\n",
      "Epoch[81], Iter: 2911, Loss: 0.00000\n",
      "Epoch[81], Iter: 2914, Loss: 0.00001\n",
      "Training Results - Epoch: 81, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[82], Iter: 2917, Loss: 0.00003\n",
      "Epoch[82], Iter: 2920, Loss: 0.00001\n",
      "Epoch[82], Iter: 2923, Loss: 0.00001\n",
      "Epoch[82], Iter: 2926, Loss: 0.00000\n",
      "Epoch[82], Iter: 2929, Loss: 0.00000\n",
      "Epoch[82], Iter: 2932, Loss: 0.00000\n",
      "Epoch[82], Iter: 2935, Loss: 0.00002\n",
      "Epoch[82], Iter: 2938, Loss: 0.00000\n",
      "Epoch[82], Iter: 2941, Loss: 0.00004\n",
      "Epoch[82], Iter: 2944, Loss: 0.00001\n",
      "Epoch[82], Iter: 2947, Loss: 0.00002\n",
      "Epoch[82], Iter: 2950, Loss: 0.00000\n",
      "Training Results - Epoch: 82, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[83], Iter: 2953, Loss: 0.00003\n",
      "Epoch[83], Iter: 2956, Loss: 0.00000\n",
      "Epoch[83], Iter: 2959, Loss: 0.00000\n",
      "Epoch[83], Iter: 2962, Loss: 0.00003\n",
      "Epoch[83], Iter: 2965, Loss: 0.00000\n",
      "Epoch[83], Iter: 2968, Loss: 0.00001\n",
      "Epoch[83], Iter: 2971, Loss: 0.00004\n",
      "Epoch[83], Iter: 2974, Loss: 0.00016\n",
      "Epoch[83], Iter: 2977, Loss: 0.00001\n",
      "Epoch[83], Iter: 2980, Loss: 0.00000\n",
      "Epoch[83], Iter: 2983, Loss: 0.00001\n",
      "Epoch[83], Iter: 2986, Loss: 0.00003\n",
      "Training Results - Epoch: 83, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[84], Iter: 2989, Loss: 0.00002\n",
      "Epoch[84], Iter: 2992, Loss: 0.00000\n",
      "Epoch[84], Iter: 2995, Loss: 0.00000\n",
      "Epoch[84], Iter: 2998, Loss: 0.00001\n",
      "Epoch[84], Iter: 3001, Loss: 0.00001\n",
      "Epoch[84], Iter: 3004, Loss: 0.00000\n",
      "Epoch[84], Iter: 3007, Loss: 0.00000\n",
      "Epoch[84], Iter: 3010, Loss: 0.00001\n",
      "Epoch[84], Iter: 3013, Loss: 0.00000\n",
      "Epoch[84], Iter: 3016, Loss: 0.00005\n",
      "Epoch[84], Iter: 3019, Loss: 0.00001\n",
      "Epoch[84], Iter: 3022, Loss: 0.00001\n",
      "Training Results - Epoch: 84, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[85], Iter: 3025, Loss: 0.00000\n",
      "Epoch[85], Iter: 3028, Loss: 0.00000\n",
      "Epoch[85], Iter: 3031, Loss: 0.00000\n",
      "Epoch[85], Iter: 3034, Loss: 0.00000\n",
      "Epoch[85], Iter: 3037, Loss: 0.00000\n",
      "Epoch[85], Iter: 3040, Loss: 0.00001\n",
      "Epoch[85], Iter: 3043, Loss: 0.00005\n",
      "Epoch[85], Iter: 3046, Loss: 0.00000\n",
      "Epoch[85], Iter: 3049, Loss: 0.00002\n",
      "Epoch[85], Iter: 3052, Loss: 0.00001\n",
      "Epoch[85], Iter: 3055, Loss: 0.00001\n",
      "Epoch[85], Iter: 3058, Loss: 0.00000\n",
      "Training Results - Epoch: 85, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[86], Iter: 3061, Loss: 0.00000\n",
      "Epoch[86], Iter: 3064, Loss: 0.00001\n",
      "Epoch[86], Iter: 3067, Loss: 0.00000\n",
      "Epoch[86], Iter: 3070, Loss: 0.00001\n",
      "Epoch[86], Iter: 3073, Loss: 0.00000\n",
      "Epoch[86], Iter: 3076, Loss: 0.00005\n",
      "Epoch[86], Iter: 3079, Loss: 0.00002\n",
      "Epoch[86], Iter: 3082, Loss: 0.00000\n",
      "Epoch[86], Iter: 3085, Loss: 0.00000\n",
      "Epoch[86], Iter: 3088, Loss: 0.00007\n",
      "Epoch[86], Iter: 3091, Loss: 0.00002\n",
      "Epoch[86], Iter: 3094, Loss: 0.00005\n",
      "Training Results - Epoch: 86, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[87], Iter: 3097, Loss: 0.00005\n",
      "Epoch[87], Iter: 3100, Loss: 0.00001\n",
      "Epoch[87], Iter: 3103, Loss: 0.00000\n",
      "Epoch[87], Iter: 3106, Loss: 0.00002\n",
      "Epoch[87], Iter: 3109, Loss: 0.00001\n",
      "Epoch[87], Iter: 3112, Loss: 0.00000\n",
      "Epoch[87], Iter: 3115, Loss: 0.00000\n",
      "Epoch[87], Iter: 3118, Loss: 0.00000\n",
      "Epoch[87], Iter: 3121, Loss: 0.00000\n",
      "Epoch[87], Iter: 3124, Loss: 0.00002\n",
      "Epoch[87], Iter: 3127, Loss: 0.00000\n",
      "Epoch[87], Iter: 3130, Loss: 0.00000\n",
      "Training Results - Epoch: 87, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[88], Iter: 3133, Loss: 0.00003\n",
      "Epoch[88], Iter: 3136, Loss: 0.00002\n",
      "Epoch[88], Iter: 3139, Loss: 0.00001\n",
      "Epoch[88], Iter: 3142, Loss: 0.00019\n",
      "Epoch[88], Iter: 3145, Loss: 0.00000\n",
      "Epoch[88], Iter: 3148, Loss: 0.00000\n",
      "Epoch[88], Iter: 3151, Loss: 0.00006\n",
      "Epoch[88], Iter: 3154, Loss: 0.00001\n",
      "Epoch[88], Iter: 3157, Loss: 0.00001\n",
      "Epoch[88], Iter: 3160, Loss: 0.00001\n",
      "Epoch[88], Iter: 3163, Loss: 0.00001\n",
      "Epoch[88], Iter: 3166, Loss: 0.00025\n",
      "Training Results - Epoch: 88, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[89], Iter: 3169, Loss: 0.00000\n",
      "Epoch[89], Iter: 3172, Loss: 0.00000\n",
      "Epoch[89], Iter: 3175, Loss: 0.00001\n",
      "Epoch[89], Iter: 3178, Loss: 0.00002\n",
      "Epoch[89], Iter: 3181, Loss: 0.00000\n",
      "Epoch[89], Iter: 3184, Loss: 0.00001\n",
      "Epoch[89], Iter: 3187, Loss: 0.00001\n",
      "Epoch[89], Iter: 3190, Loss: 0.00002\n",
      "Epoch[89], Iter: 3193, Loss: 0.00007\n",
      "Epoch[89], Iter: 3196, Loss: 0.00001\n",
      "Epoch[89], Iter: 3199, Loss: 0.00004\n",
      "Epoch[89], Iter: 3202, Loss: 0.00000\n",
      "Training Results - Epoch: 89, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[90], Iter: 3205, Loss: 0.00037\n",
      "Epoch[90], Iter: 3208, Loss: 0.00008\n",
      "Epoch[90], Iter: 3211, Loss: 0.00000\n",
      "Epoch[90], Iter: 3214, Loss: 0.00001\n",
      "Epoch[90], Iter: 3217, Loss: 0.00000\n",
      "Epoch[90], Iter: 3220, Loss: 0.00000\n",
      "Epoch[90], Iter: 3223, Loss: 0.00000\n",
      "Epoch[90], Iter: 3226, Loss: 0.00001\n",
      "Epoch[90], Iter: 3229, Loss: 0.00000\n",
      "Epoch[90], Iter: 3232, Loss: 0.00000\n",
      "Epoch[90], Iter: 3235, Loss: 0.00003\n",
      "Epoch[90], Iter: 3238, Loss: 0.00002\n",
      "Training Results - Epoch: 90, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[91], Iter: 3241, Loss: 0.00000\n",
      "Epoch[91], Iter: 3244, Loss: 0.00000\n",
      "Epoch[91], Iter: 3247, Loss: 0.00000\n",
      "Epoch[91], Iter: 3250, Loss: 0.00001\n",
      "Epoch[91], Iter: 3253, Loss: 0.00001\n",
      "Epoch[91], Iter: 3256, Loss: 0.00000\n",
      "Epoch[91], Iter: 3259, Loss: 0.00000\n",
      "Epoch[91], Iter: 3262, Loss: 0.00000\n",
      "Epoch[91], Iter: 3265, Loss: 0.00003\n",
      "Epoch[91], Iter: 3268, Loss: 0.00000\n",
      "Epoch[91], Iter: 3271, Loss: 0.00005\n",
      "Epoch[91], Iter: 3274, Loss: 0.00004\n",
      "Training Results - Epoch: 91, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[92], Iter: 3277, Loss: 0.00012\n",
      "Epoch[92], Iter: 3280, Loss: 0.00000\n",
      "Epoch[92], Iter: 3283, Loss: 0.00002\n",
      "Epoch[92], Iter: 3286, Loss: 0.00002\n",
      "Epoch[92], Iter: 3289, Loss: 0.00001\n",
      "Epoch[92], Iter: 3292, Loss: 0.00003\n",
      "Epoch[92], Iter: 3295, Loss: 0.00005\n",
      "Epoch[92], Iter: 3298, Loss: 0.00003\n",
      "Epoch[92], Iter: 3301, Loss: 0.00009\n",
      "Epoch[92], Iter: 3304, Loss: 0.00000\n",
      "Epoch[92], Iter: 3307, Loss: 0.00001\n",
      "Epoch[92], Iter: 3310, Loss: 0.00003\n",
      "Training Results - Epoch: 92, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[93], Iter: 3313, Loss: 0.00000\n",
      "Epoch[93], Iter: 3316, Loss: 0.00000\n",
      "Epoch[93], Iter: 3319, Loss: 0.00002\n",
      "Epoch[93], Iter: 3322, Loss: 0.00050\n",
      "Epoch[93], Iter: 3325, Loss: 0.00000\n",
      "Epoch[93], Iter: 3328, Loss: 0.00007\n",
      "Epoch[93], Iter: 3331, Loss: 0.00000\n",
      "Epoch[93], Iter: 3334, Loss: 0.00016\n",
      "Epoch[93], Iter: 3337, Loss: 0.00020\n",
      "Epoch[93], Iter: 3340, Loss: 0.00001\n",
      "Epoch[93], Iter: 3343, Loss: 0.00012\n",
      "Epoch[93], Iter: 3346, Loss: 0.00000\n",
      "Training Results - Epoch: 93, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[94], Iter: 3349, Loss: 0.00000\n",
      "Epoch[94], Iter: 3352, Loss: 0.00000\n",
      "Epoch[94], Iter: 3355, Loss: 0.00000\n",
      "Epoch[94], Iter: 3358, Loss: 0.00000\n",
      "Epoch[94], Iter: 3361, Loss: 0.00001\n",
      "Epoch[94], Iter: 3364, Loss: 0.00000\n",
      "Epoch[94], Iter: 3367, Loss: 0.00002\n",
      "Epoch[94], Iter: 3370, Loss: 0.00002\n",
      "Epoch[94], Iter: 3373, Loss: 0.00000\n",
      "Epoch[94], Iter: 3376, Loss: 0.00000\n",
      "Epoch[94], Iter: 3379, Loss: 0.00005\n",
      "Epoch[94], Iter: 3382, Loss: 0.00000\n",
      "Training Results - Epoch: 94, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[95], Iter: 3385, Loss: 0.00003\n",
      "Epoch[95], Iter: 3388, Loss: 0.00000\n",
      "Epoch[95], Iter: 3391, Loss: 0.00002\n",
      "Epoch[95], Iter: 3394, Loss: 0.00000\n",
      "Epoch[95], Iter: 3397, Loss: 0.00000\n",
      "Epoch[95], Iter: 3400, Loss: 0.00007\n",
      "Epoch[95], Iter: 3403, Loss: 0.00005\n",
      "Epoch[95], Iter: 3406, Loss: 0.00001\n",
      "Epoch[95], Iter: 3409, Loss: 0.00001\n",
      "Epoch[95], Iter: 3412, Loss: 0.00000\n",
      "Epoch[95], Iter: 3415, Loss: 0.00007\n",
      "Epoch[95], Iter: 3418, Loss: 0.00001\n",
      "Training Results - Epoch: 95, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[96], Iter: 3421, Loss: 0.00010\n",
      "Epoch[96], Iter: 3424, Loss: 0.00001\n",
      "Epoch[96], Iter: 3427, Loss: 0.00001\n",
      "Epoch[96], Iter: 3430, Loss: 0.00000\n",
      "Epoch[96], Iter: 3433, Loss: 0.00003\n",
      "Epoch[96], Iter: 3436, Loss: 0.00000\n",
      "Epoch[96], Iter: 3439, Loss: 0.00000\n",
      "Epoch[96], Iter: 3442, Loss: 0.00000\n",
      "Epoch[96], Iter: 3445, Loss: 0.00007\n",
      "Epoch[96], Iter: 3448, Loss: 0.00001\n",
      "Epoch[96], Iter: 3451, Loss: 0.00000\n",
      "Epoch[96], Iter: 3454, Loss: 0.00000\n",
      "Training Results - Epoch: 96, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[97], Iter: 3457, Loss: 0.00000\n",
      "Epoch[97], Iter: 3460, Loss: 0.00002\n",
      "Epoch[97], Iter: 3463, Loss: 0.00003\n",
      "Epoch[97], Iter: 3466, Loss: 0.00000\n",
      "Epoch[97], Iter: 3469, Loss: 0.00004\n",
      "Epoch[97], Iter: 3472, Loss: 0.00002\n",
      "Epoch[97], Iter: 3475, Loss: 0.00001\n",
      "Epoch[97], Iter: 3478, Loss: 0.00000\n",
      "Epoch[97], Iter: 3481, Loss: 0.00000\n",
      "Epoch[97], Iter: 3484, Loss: 0.00000\n",
      "Epoch[97], Iter: 3487, Loss: 0.00001\n",
      "Epoch[97], Iter: 3490, Loss: 0.00001\n",
      "Training Results - Epoch: 97, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[98], Iter: 3493, Loss: 0.00001\n",
      "Epoch[98], Iter: 3496, Loss: 0.00000\n",
      "Epoch[98], Iter: 3499, Loss: 0.00004\n",
      "Epoch[98], Iter: 3502, Loss: 0.00000\n",
      "Epoch[98], Iter: 3505, Loss: 0.00002\n",
      "Epoch[98], Iter: 3508, Loss: 0.00000\n",
      "Epoch[98], Iter: 3511, Loss: 0.00000\n",
      "Epoch[98], Iter: 3514, Loss: 0.00000\n",
      "Epoch[98], Iter: 3517, Loss: 0.00000\n",
      "Epoch[98], Iter: 3520, Loss: 0.00008\n",
      "Epoch[98], Iter: 3523, Loss: 0.00000\n",
      "Epoch[98], Iter: 3526, Loss: 0.00002\n",
      "Training Results - Epoch: 98, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[99], Iter: 3529, Loss: 0.00000\n",
      "Epoch[99], Iter: 3532, Loss: 0.00000\n",
      "Epoch[99], Iter: 3535, Loss: 0.00000\n",
      "Epoch[99], Iter: 3538, Loss: 0.00000\n",
      "Epoch[99], Iter: 3541, Loss: 0.00000\n",
      "Epoch[99], Iter: 3544, Loss: 0.00002\n",
      "Epoch[99], Iter: 3547, Loss: 0.00001\n",
      "Epoch[99], Iter: 3550, Loss: 0.00010\n",
      "Epoch[99], Iter: 3553, Loss: 0.00001\n",
      "Epoch[99], Iter: 3556, Loss: 0.00003\n",
      "Epoch[99], Iter: 3559, Loss: 0.00000\n",
      "Epoch[99], Iter: 3562, Loss: 0.00004\n",
      "Training Results - Epoch: 99, Accuracy: 1.00000, Avg loss: 0.00000\n",
      "Epoch[100], Iter: 3565, Loss: 0.00001\n",
      "Epoch[100], Iter: 3568, Loss: 0.00003\n",
      "Epoch[100], Iter: 3571, Loss: 0.00001\n",
      "Epoch[100], Iter: 3574, Loss: 0.00000\n",
      "Epoch[100], Iter: 3577, Loss: 0.00000\n",
      "Epoch[100], Iter: 3580, Loss: 0.00000\n",
      "Epoch[100], Iter: 3583, Loss: 0.00001\n",
      "Epoch[100], Iter: 3586, Loss: 0.00001\n",
      "Epoch[100], Iter: 3589, Loss: 0.00002\n",
      "Epoch[100], Iter: 3592, Loss: 0.00000\n",
      "Epoch[100], Iter: 3595, Loss: 0.00000\n",
      "Epoch[100], Iter: 3598, Loss: 0.00001\n",
      "Training Results - Epoch: 100, Accuracy: 1.00000, Avg loss: 0.00000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ignite.engine.engine.State at 0x2b7eb5231f28>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.run(train_loader, max_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
