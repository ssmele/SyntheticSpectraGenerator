{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthetic_torch_helpers import SynH5Dataset, ConvModSyn\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Loss, Metric\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SynH5Dataset(filename=\"syn_flux_dataset_v2.h5\", load_to_memory=True)\n",
    "val_dataset = SynH5Dataset(filename=\"syn_flux_dataset_v2_val.h5\", load_to_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centering the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.zs -= np.mean(train_dataset.zs, axis=0)\n",
    "train_dataset.flux -= np.mean(train_dataset.flux, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset.zs -= np.mean(val_dataset.zs, axis=0)\n",
    "val_dataset.flux -= np.mean(val_dataset.flux, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mss = MinMaxScaler()\n",
    "train_dataset.zs = z_mss.fit_transform(train_dataset.zs)\n",
    "val_dataset.zs = z_mss.transform(val_dataset.zs)\n",
    "\n",
    "flux_mss = MinMaxScaler()\n",
    "train_dataset.flux = flux_mss.fit_transform(train_dataset.flux[:, 0, :]).reshape(-1, 1, 4563)\n",
    "val_dataset.flux = flux_mss.transform(val_dataset.flux[:, 0, :]).reshape(-1, 1, 4563)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=2048, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvModSyn(\n",
       "  (conv_layers): Sequential(\n",
       "    (conv_0): Sequential(\n",
       "      (0): Conv1d(1, 64, kernel_size=(15,), stride=(1,))\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv_1): Sequential(\n",
       "      (0): Conv1d(64, 32, kernel_size=(10,), stride=(1,))\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv_2): Sequential(\n",
       "      (0): Conv1d(32, 16, kernel_size=(5,), stride=(1,))\n",
       "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv_3): Sequential(\n",
       "      (0): Conv1d(16, 8, kernel_size=(5,), stride=(1,))\n",
       "      (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (pool_3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv_4): Sequential(\n",
       "      (0): Conv1d(8, 4, kernel_size=(3,), stride=(1,))\n",
       "      (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv_5): Sequential(\n",
       "      (0): Conv1d(4, 2, kernel_size=(3,), stride=(1,))\n",
       "      (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (pool_5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (fc_0): Sequential(\n",
       "      (0): Linear(in_features=1126, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (dropout_0): Dropout(p=0.5)\n",
       "    (fc_1): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (dropout_1): Dropout(p=0.5)\n",
       "    (fc_4): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (final_act): Sequential()\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_config = [\n",
    "    (1, 64, 15),\n",
    "    (64, 32, 10),\n",
    "#     Drop out\n",
    "    (32, 16, 5),\n",
    "    (16, 8, 5),\n",
    "#     Drop out\n",
    "    (8, 4, 3),\n",
    "    (4, 2, 3)\n",
    "]\n",
    "\n",
    "full_config = [\n",
    "    (1126, 512),\n",
    "    (512, 256),\n",
    "    (256, 1)\n",
    "]\n",
    "\n",
    "dropout_ixs = {0: .5, 1 : .5, 2: .5}\n",
    "pooling_ixs = {1 : 2, 3: 2, 5: 2}\n",
    "mod = ConvModSyn(conv_config, full_config, pooling_ixs, dropout_ixs, torch.nn.Sequential())\n",
    "mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(mod.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up gpu device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CustonMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SciStandard(Metric):\n",
    "    \"\"\"\n",
    "    Calculates metric to determine how many predictions are within scientific standard.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, output_transform=lambda x: x, z_tol=None):\n",
    "        super(SciStandard, self).__init__(output_transform)\n",
    "        if z_tol is None:\n",
    "            kms = 300\n",
    "            c = 299792.458 #Speed of Light in kms\n",
    "            self._z_tol = np.sqrt((1+kms/c)/(1-kms/c))-1\n",
    "        else:\n",
    "            self._z_tol = z_tol\n",
    "    \n",
    "    def reset(self):\n",
    "        self._total_in = 0.0\n",
    "        self._num_examples = 0\n",
    "\n",
    "    def update(self, output):\n",
    "        y_pred, y = output\n",
    "        y_pred, y = z_mss.inverse_transform(y_pred.cpu()), z_mss.inverse_transform(y.cpu())\n",
    "        self._total_in += np.sum(np.abs(y_pred - y) <= self._z_tol)\n",
    "        self._num_examples += len(y)\n",
    "\n",
    "    def compute(self):\n",
    "        if self._num_examples == 0:\n",
    "            raise NotComputableError('SciStandard must have at least one example before it can be computed.')\n",
    "        return self._total_in # self._num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up trainer and evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = create_supervised_trainer(mod, opt, loss, device=device)\n",
    "evaluator = create_supervised_evaluator(mod, metrics={'mse': Loss(loss), 'sci': SciStandard()}, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saver = ModelCheckpoint(\"./models/sess_{}/\".format(datetime.datetime.now()), \"reg\", create_dir=True, \n",
    "                              score_function=lambda eng: eng.state.val_standard, score_name='val_loss', n_saved=5)\n",
    "early_stopper = EarlyStopping(20, score_function=lambda eng: eng.state.val_loss, trainer=trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Events (Experimenting with ignite for pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_level = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(trainer):\n",
    "    if (trainer.state.iteration-1) % iter_level == 0:\n",
    "        print(\"Epoch[{}], Iter: {}, Loss: {:.5f}\".format(trainer.state.epoch, trainer.state.iteration, trainer.state.output))\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    evaluator.run(train_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    trainer.state.train_loss = metrics['mse']\n",
    "    print(\"Training Results - Epoch: {}, SciStandard: {:.5f}, Avg loss: {:.5f}\".format(trainer.state.epoch, metrics['sci'], metrics['mse']))\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    trainer.state.val_loss = metrics['mse']\n",
    "    trainer.state.val_standard = metrics['sci']\n",
    "    print(\"Validation Results - Epoch: {}, SciStandard: {:.5f}, Avg loss: {:.5f}\".format(trainer.state.epoch, metrics['sci'], metrics['mse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, model_saver, {'mod': mod})\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, early_stopper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1], Iter: 1, Loss: 0.51415\n",
      "Epoch[1], Iter: 51, Loss: 0.10536\n",
      "Epoch[1], Iter: 101, Loss: 0.08272\n",
      "Epoch[1], Iter: 151, Loss: 0.07481\n",
      "Epoch[1], Iter: 201, Loss: 0.07204\n",
      "Epoch[1], Iter: 251, Loss: 0.04241\n",
      "Epoch[1], Iter: 301, Loss: 0.01993\n",
      "Epoch[1], Iter: 351, Loss: 0.01826\n",
      "Epoch[1], Iter: 401, Loss: 0.01406\n",
      "Epoch[1], Iter: 451, Loss: 0.01599\n",
      "Epoch[1], Iter: 501, Loss: 0.01270\n",
      "Epoch[1], Iter: 551, Loss: 0.01307\n",
      "Epoch[1], Iter: 601, Loss: 0.01185\n",
      "Epoch[1], Iter: 651, Loss: 0.01589\n",
      "Epoch[1], Iter: 701, Loss: 0.01016\n",
      "Epoch[1], Iter: 751, Loss: 0.01558\n",
      "Epoch[1], Iter: 801, Loss: 0.01099\n",
      "Epoch[1], Iter: 851, Loss: 0.01418\n",
      "Epoch[1], Iter: 901, Loss: 0.01192\n",
      "Epoch[1], Iter: 951, Loss: 0.00872\n",
      "Epoch[1], Iter: 1001, Loss: 0.00561\n",
      "Epoch[1], Iter: 1051, Loss: 0.00601\n",
      "Epoch[1], Iter: 1101, Loss: 0.01228\n",
      "Epoch[1], Iter: 1151, Loss: 0.01427\n",
      "Epoch[1], Iter: 1201, Loss: 0.00746\n",
      "Epoch[1], Iter: 1251, Loss: 0.00595\n",
      "Epoch[1], Iter: 1301, Loss: 0.00927\n",
      "Epoch[1], Iter: 1351, Loss: 0.00894\n",
      "Epoch[1], Iter: 1401, Loss: 0.00527\n",
      "Epoch[1], Iter: 1451, Loss: 0.00682\n",
      "Epoch[1], Iter: 1501, Loss: 0.00592\n",
      "Epoch[1], Iter: 1551, Loss: 0.00471\n",
      "Training Results - Epoch: 1, SciStandard: 28326.00000, Avg loss: 0.00433\n",
      "Validation Results - Epoch: 1, SciStandard: 7107.00000, Avg loss: 0.00426\n",
      "Epoch[2], Iter: 1601, Loss: 0.00500\n",
      "Epoch[2], Iter: 1651, Loss: 0.00432\n",
      "Epoch[2], Iter: 1701, Loss: 0.00581\n",
      "Epoch[2], Iter: 1751, Loss: 0.00622\n",
      "Epoch[2], Iter: 1801, Loss: 0.00434\n",
      "Epoch[2], Iter: 1851, Loss: 0.00552\n",
      "Epoch[2], Iter: 1901, Loss: 0.00561\n",
      "Epoch[2], Iter: 1951, Loss: 0.00584\n",
      "Epoch[2], Iter: 2001, Loss: 0.00495\n",
      "Epoch[2], Iter: 2051, Loss: 0.00371\n",
      "Epoch[2], Iter: 2101, Loss: 0.00366\n",
      "Epoch[2], Iter: 2151, Loss: 0.00359\n",
      "Epoch[2], Iter: 2201, Loss: 0.00421\n",
      "Epoch[2], Iter: 2251, Loss: 0.00360\n",
      "Epoch[2], Iter: 2301, Loss: 0.00463\n",
      "Epoch[2], Iter: 2351, Loss: 0.00248\n",
      "Epoch[2], Iter: 2401, Loss: 0.00568\n",
      "Epoch[2], Iter: 2451, Loss: 0.00462\n",
      "Epoch[2], Iter: 2501, Loss: 0.00597\n",
      "Epoch[2], Iter: 2551, Loss: 0.00391\n",
      "Epoch[2], Iter: 2601, Loss: 0.00621\n",
      "Epoch[2], Iter: 2651, Loss: 0.00290\n",
      "Epoch[2], Iter: 2701, Loss: 0.00291\n",
      "Epoch[2], Iter: 2751, Loss: 0.00379\n",
      "Epoch[2], Iter: 2801, Loss: 0.00263\n",
      "Epoch[2], Iter: 2851, Loss: 0.00519\n",
      "Epoch[2], Iter: 2901, Loss: 0.00328\n",
      "Epoch[2], Iter: 2951, Loss: 0.00236\n",
      "Epoch[2], Iter: 3001, Loss: 0.00218\n",
      "Epoch[2], Iter: 3051, Loss: 0.00377\n",
      "Epoch[2], Iter: 3101, Loss: 0.00330\n",
      "Training Results - Epoch: 2, SciStandard: 53283.00000, Avg loss: 0.00206\n",
      "Validation Results - Epoch: 2, SciStandard: 13291.00000, Avg loss: 0.00209\n",
      "Epoch[3], Iter: 3151, Loss: 0.00438\n",
      "Epoch[3], Iter: 3201, Loss: 0.00335\n",
      "Epoch[3], Iter: 3251, Loss: 0.00240\n",
      "Epoch[3], Iter: 3301, Loss: 0.00521\n",
      "Epoch[3], Iter: 3351, Loss: 0.00223\n",
      "Epoch[3], Iter: 3401, Loss: 0.00424\n",
      "Epoch[3], Iter: 3451, Loss: 0.00233\n",
      "Epoch[3], Iter: 3501, Loss: 0.00194\n",
      "Epoch[3], Iter: 3551, Loss: 0.00233\n",
      "Epoch[3], Iter: 3601, Loss: 0.00236\n",
      "Epoch[3], Iter: 3651, Loss: 0.00207\n",
      "Epoch[3], Iter: 3701, Loss: 0.00328\n",
      "Epoch[3], Iter: 3751, Loss: 0.00249\n",
      "Epoch[3], Iter: 3801, Loss: 0.00262\n",
      "Epoch[3], Iter: 3851, Loss: 0.00273\n",
      "Epoch[3], Iter: 3901, Loss: 0.00154\n",
      "Epoch[3], Iter: 3951, Loss: 0.00363\n",
      "Epoch[3], Iter: 4001, Loss: 0.00171\n",
      "Epoch[3], Iter: 4051, Loss: 0.00150\n",
      "Epoch[3], Iter: 4101, Loss: 0.00193\n",
      "Epoch[3], Iter: 4151, Loss: 0.00294\n",
      "Epoch[3], Iter: 4201, Loss: 0.00173\n",
      "Epoch[3], Iter: 4251, Loss: 0.00144\n",
      "Epoch[3], Iter: 4301, Loss: 0.00295\n",
      "Epoch[3], Iter: 4351, Loss: 0.00522\n",
      "Epoch[3], Iter: 4401, Loss: 0.00185\n",
      "Epoch[3], Iter: 4451, Loss: 0.00170\n",
      "Epoch[3], Iter: 4501, Loss: 0.00182\n",
      "Epoch[3], Iter: 4551, Loss: 0.00165\n",
      "Epoch[3], Iter: 4601, Loss: 0.00153\n",
      "Epoch[3], Iter: 4651, Loss: 0.00410\n",
      "Training Results - Epoch: 3, SciStandard: 62231.00000, Avg loss: 0.00209\n",
      "Validation Results - Epoch: 3, SciStandard: 15647.00000, Avg loss: 0.00214\n",
      "Epoch[4], Iter: 4701, Loss: 0.00208\n",
      "Epoch[4], Iter: 4751, Loss: 0.00128\n",
      "Epoch[4], Iter: 4801, Loss: 0.00204\n",
      "Epoch[4], Iter: 4851, Loss: 0.00183\n",
      "Epoch[4], Iter: 4901, Loss: 0.00131\n",
      "Epoch[4], Iter: 4951, Loss: 0.00163\n",
      "Epoch[4], Iter: 5001, Loss: 0.00253\n",
      "Epoch[4], Iter: 5051, Loss: 0.00152\n",
      "Epoch[4], Iter: 5101, Loss: 0.00439\n",
      "Epoch[4], Iter: 5151, Loss: 0.00283\n",
      "Epoch[4], Iter: 5201, Loss: 0.00133\n",
      "Epoch[4], Iter: 5251, Loss: 0.00163\n",
      "Epoch[4], Iter: 5301, Loss: 0.00156\n",
      "Epoch[4], Iter: 5351, Loss: 0.00724\n",
      "Epoch[4], Iter: 5401, Loss: 0.00174\n",
      "Epoch[4], Iter: 5451, Loss: 0.00219\n",
      "Epoch[4], Iter: 5501, Loss: 0.00147\n",
      "Epoch[4], Iter: 5551, Loss: 0.00119\n",
      "Epoch[4], Iter: 5601, Loss: 0.00340\n",
      "Epoch[4], Iter: 5651, Loss: 0.00227\n",
      "Epoch[4], Iter: 5701, Loss: 0.00187\n",
      "Epoch[4], Iter: 5751, Loss: 0.00127\n",
      "Epoch[4], Iter: 5801, Loss: 0.00481\n",
      "Epoch[4], Iter: 5851, Loss: 0.00281\n",
      "Epoch[4], Iter: 5901, Loss: 0.00102\n",
      "Epoch[4], Iter: 5951, Loss: 0.00191\n",
      "Epoch[4], Iter: 6001, Loss: 0.00107\n",
      "Epoch[4], Iter: 6051, Loss: 0.00319\n",
      "Epoch[4], Iter: 6101, Loss: 0.00164\n",
      "Epoch[4], Iter: 6151, Loss: 0.00211\n",
      "Epoch[4], Iter: 6201, Loss: 0.00200\n",
      "Epoch[4], Iter: 6251, Loss: 0.00198\n",
      "Training Results - Epoch: 4, SciStandard: 111590.00000, Avg loss: 0.00162\n",
      "Validation Results - Epoch: 4, SciStandard: 27777.00000, Avg loss: 0.00168\n",
      "Epoch[5], Iter: 6301, Loss: 0.00293\n",
      "Epoch[5], Iter: 6351, Loss: 0.00198\n",
      "Epoch[5], Iter: 6401, Loss: 0.00133\n",
      "Epoch[5], Iter: 6451, Loss: 0.00321\n",
      "Epoch[5], Iter: 6501, Loss: 0.00298\n",
      "Epoch[5], Iter: 6551, Loss: 0.00119\n",
      "Epoch[5], Iter: 6601, Loss: 0.00157\n",
      "Epoch[5], Iter: 6651, Loss: 0.00131\n",
      "Epoch[5], Iter: 6701, Loss: 0.00132\n",
      "Epoch[5], Iter: 6751, Loss: 0.00155\n",
      "Epoch[5], Iter: 6801, Loss: 0.00091\n",
      "Epoch[5], Iter: 6851, Loss: 0.00147\n",
      "Epoch[5], Iter: 6901, Loss: 0.00194\n",
      "Epoch[5], Iter: 6951, Loss: 0.00165\n",
      "Epoch[5], Iter: 7001, Loss: 0.00138\n",
      "Epoch[5], Iter: 7051, Loss: 0.00210\n",
      "Epoch[5], Iter: 7101, Loss: 0.00202\n",
      "Epoch[5], Iter: 7151, Loss: 0.00140\n",
      "Epoch[5], Iter: 7201, Loss: 0.00249\n",
      "Epoch[5], Iter: 7251, Loss: 0.00640\n",
      "Epoch[5], Iter: 7301, Loss: 0.00138\n",
      "Epoch[5], Iter: 7351, Loss: 0.00229\n",
      "Epoch[5], Iter: 7401, Loss: 0.00394\n",
      "Epoch[5], Iter: 7451, Loss: 0.00176\n",
      "Epoch[5], Iter: 7501, Loss: 0.00270\n",
      "Epoch[5], Iter: 7551, Loss: 0.00116\n",
      "Epoch[5], Iter: 7601, Loss: 0.00102\n",
      "Epoch[5], Iter: 7651, Loss: 0.00193\n",
      "Epoch[5], Iter: 7701, Loss: 0.00134\n",
      "Epoch[5], Iter: 7751, Loss: 0.00116\n",
      "Epoch[5], Iter: 7801, Loss: 0.00291\n",
      "Training Results - Epoch: 5, SciStandard: 18982.00000, Avg loss: 0.02889\n",
      "Validation Results - Epoch: 5, SciStandard: 4833.00000, Avg loss: 0.02881\n",
      "Epoch[6], Iter: 7851, Loss: 0.00342\n",
      "Epoch[6], Iter: 7901, Loss: 0.00405\n",
      "Epoch[6], Iter: 7951, Loss: 0.00211\n",
      "Epoch[6], Iter: 8001, Loss: 0.00167\n",
      "Epoch[6], Iter: 8051, Loss: 0.00180\n",
      "Epoch[6], Iter: 8101, Loss: 0.00280\n",
      "Epoch[6], Iter: 8151, Loss: 0.00129\n",
      "Epoch[6], Iter: 8201, Loss: 0.00245\n",
      "Epoch[6], Iter: 8251, Loss: 0.00656\n",
      "Epoch[6], Iter: 8301, Loss: 0.00139\n",
      "Epoch[6], Iter: 8351, Loss: 0.00116\n",
      "Epoch[6], Iter: 8401, Loss: 0.00249\n",
      "Epoch[6], Iter: 8451, Loss: 0.00185\n",
      "Epoch[6], Iter: 8501, Loss: 0.00122\n",
      "Epoch[6], Iter: 8551, Loss: 0.00212\n",
      "Epoch[6], Iter: 8601, Loss: 0.00216\n",
      "Epoch[6], Iter: 8651, Loss: 0.00153\n",
      "Epoch[6], Iter: 8701, Loss: 0.00087\n"
     ]
    }
   ],
   "source": [
    "trainer.run(train_loader, max_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many in desired range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010011934795353117"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kms = 300\n",
    "c = 299792.458 #Speed of Light in kms\n",
    "delta_z_tolerance = np.sqrt((1+kms/c)/(1-kms/c))-1\n",
    "delta_z_tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvModSyn(\n",
       "  (conv_layers): Sequential(\n",
       "    (conv_0): Sequential(\n",
       "      (0): Conv1d(1, 64, kernel_size=(10,), stride=(1,))\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv_1): Sequential(\n",
       "      (0): Conv1d(64, 32, kernel_size=(2,), stride=(1,))\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (fc_0): Sequential(\n",
       "      (0): Linear(in_features=72832, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (dropout_0): Dropout(p=0.5)\n",
       "    (fc_1): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (dropout_1): Dropout(p=0.5)\n",
       "    (fc_2): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (fc_5): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (final_act): Sequential()\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.load_state_dict(torch.load(\"./models/sess_2019-06-12 14:38:20.542320/reg_mod_2_val_loss=0.002978609.pth\"))\n",
    "mod.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.eval()\n",
    "with torch.no_grad():\n",
    "    ttl = 0\n",
    "    for X, y in val_loader:\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "        diff = mod(X) - y\n",
    "        ttl += torch.sum(torch.abs(diff) <= delta_z_tolerance)\n",
    "#         ttl += torch.sum((diff <= delta_z_tolerance) & (diff >= -delta_z_tolerance))\n",
    "    ttl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01388"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttl.item()/len(val_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
